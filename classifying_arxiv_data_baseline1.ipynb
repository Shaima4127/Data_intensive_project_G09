{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import pyspark\n",
    "import time\n",
    "from pyspark.sql import SparkSession \n",
    "from pyspark.sql.functions import *\n",
    "from pyspark.sql.types import *\n",
    "from pyspark.sql.functions import col, split, when, count\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.classification import LogisticRegression, RandomForestClassifier, LinearSVC, NaiveBayes\n",
    "from pyspark.ml.feature import HashingTF, Tokenizer\n",
    "from pyspark.ml.feature import StringIndexer, RegexTokenizer, StopWordsRemover, CountVectorizer, IDF\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "from pyspark.sql.functions import concat_ws\n",
    "from delta import DeltaTable, configure_spark_with_delta_pip\n",
    "\n",
    "partition = 0\n",
    "test_ratio = 0.2\n",
    "bprint = 1\n",
    "filepath = 'hdfs:///Dat500_Group09/output_meta/part*'\n",
    "# set the path to the Delta table\n",
    "delta_table_path = \"hdfs:///Dat500_Group09/result/arxiv_meta\"\n",
    "\n",
    "\n",
    "#filepath = 'hdfs:///Dat500_Group09/output_meta/part*'\n",
    "#delta_table_path = \"hdfs:///Dat500_Group09/result/arxiv_sample\"   \n",
    "\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Create_ML_pipline(ML_model = \"LR\"):\n",
    "  # Convert the main_category column to numeric using StringIndexer\n",
    "  labelIndexer = StringIndexer(inputCol=\"main_category\", outputCol=\"label\")\n",
    "\n",
    "  # Define the regular expression tokenizer\n",
    "  regexTokenizer = RegexTokenizer(inputCol=\"text\", outputCol=\"tokens\", pattern=\"\\\\W\")\n",
    "\n",
    "  # Define the stop words remover\n",
    "  stopWordsRemover = StopWordsRemover(inputCol=\"tokens\", outputCol=\"filtered_tokens\")\n",
    "\n",
    "  # Define the TF-IDF Vectorizer\n",
    "  countVectorizer = CountVectorizer(inputCol=\"filtered_tokens\", outputCol=\"vectorize_features\")\n",
    "  # hashingTF = HashingTF(inputCol=\"words\", outputCol=\"rawFeatures\", numFeatures=20)\n",
    "  idf = IDF(inputCol=\"vectorize_features\", outputCol=\"features\")\n",
    "\n",
    "  if ML_model == 'LR': # Create logistic regression classifier     \n",
    "    ML_Model = LogisticRegression(featuresCol=\"features\", labelCol=\"label\", maxIter=100)\n",
    "  elif ML_model == 'RF': # Create a Random Forest classifier\n",
    "    ML_Model = RandomForestClassifier(numTrees=500, maxDepth=5, labelCol=\"label\", featuresCol=\"features\")\n",
    "  elif ML_model == 'NB': # Create a Naive Bayes classifier\n",
    "    ML_Model = NaiveBayes(modelType=\"multinomial\", labelCol=\"label\", featuresCol=\"features\")\n",
    "\n",
    "  # Define the Pipeline\n",
    "  pipeline = Pipeline(stages=[labelIndexer, regexTokenizer, stopWordsRemover, countVectorizer, idf, ML_Model])\n",
    "\n",
    "  return pipeline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ":: loading settings :: url = jar:file:/home/ubuntu/.local/lib/python3.8/site-packages/pyspark/jars/ivy-2.5.1.jar!/org/apache/ivy/core/settings/ivysettings.xml\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Ivy Default Cache set to: /home/ubuntu/.ivy2/cache\n",
      "The jars for the packages stored in: /home/ubuntu/.ivy2/jars\n",
      "io.delta#delta-core_2.12 added as a dependency\n",
      ":: resolving dependencies :: org.apache.spark#spark-submit-parent-454edaf2-fbb5-45ff-800a-32e512fd7a99;1.0\n",
      "\tconfs: [default]\n",
      "\tfound io.delta#delta-core_2.12;2.3.0 in central\n",
      "\tfound io.delta#delta-storage;2.3.0 in central\n",
      "\tfound org.antlr#antlr4-runtime;4.8 in central\n",
      ":: resolution report :: resolve 209ms :: artifacts dl 10ms\n",
      "\t:: modules in use:\n",
      "\tio.delta#delta-core_2.12;2.3.0 from central in [default]\n",
      "\tio.delta#delta-storage;2.3.0 from central in [default]\n",
      "\torg.antlr#antlr4-runtime;4.8 from central in [default]\n",
      "\t---------------------------------------------------------------------\n",
      "\t|                  |            modules            ||   artifacts   |\n",
      "\t|       conf       | number| search|dwnlded|evicted|| number|dwnlded|\n",
      "\t---------------------------------------------------------------------\n",
      "\t|      default     |   3   |   0   |   0   |   0   ||   3   |   0   |\n",
      "\t---------------------------------------------------------------------\n",
      ":: retrieving :: org.apache.spark#spark-submit-parent-454edaf2-fbb5-45ff-800a-32e512fd7a99\n",
      "\tconfs: [default]\n",
      "\t0 artifacts copied, 3 already retrieved (0kB/8ms)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/04/21 02:16:58 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/04/21 02:17:02 WARN Client: Neither spark.yarn.jars nor spark.yarn.archive is set, falling back to uploading libraries under SPARK_HOME.\n",
      "23/04/21 02:17:13 WARN Client: Same path resource file:///home/ubuntu/.ivy2/jars/io.delta_delta-core_2.12-2.3.0.jar added multiple times to distributed cache.\n",
      "23/04/21 02:17:13 WARN Client: Same path resource file:///home/ubuntu/.ivy2/jars/io.delta_delta-storage-2.3.0.jar added multiple times to distributed cache.\n",
      "23/04/21 02:17:13 WARN Client: Same path resource file:///home/ubuntu/.ivy2/jars/org.antlr_antlr4-runtime-4.8.jar added multiple times to distributed cache.\n"
     ]
    }
   ],
   "source": [
    "  # Set the configuration properties for Delta tables\n",
    "builder = pyspark.sql.SparkSession.builder.appName(\"Arxiv_Classification\") \\\n",
    "    .master('yarn') \\\n",
    "    .config(\"spark.sql.extensions\", \"io.delta.sql.DeltaSparkSessionExtension\") \\\n",
    "    .config(\"spark.sql.catalog.spark_catalog\", \"org.apache.spark.sql.delta.catalog.DeltaCatalog\")\\\n",
    "    .config('spark.driver.memory', '2g')\n",
    "  \n",
    "spark = configure_spark_with_delta_pip(builder).getOrCreate()\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#spark.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create the schema for our dataset to determine the datatype for each columns)\n",
    "dbschema = StructType([\n",
    "    StructField(\"id\", StringType(), True),\n",
    "    StructField(\"authors\", StringType(), True),\n",
    "    StructField(\"title\", StringType(), True),\n",
    "    StructField(\"abstract\", StringType(), True),\n",
    "    StructField(\"journal_ref\", StringType(), True),\n",
    "    StructField(\"category\", StringType(), True),\n",
    "    StructField(\"update_date\", StringType(), True),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# import csv file for the data\n",
    "try:\n",
    "  arxiv_df =spark.read.options(delimiter=\"::\", header=False, schema=dbschema).csv(filepath)    \n",
    "except:\n",
    "    print(f\"Error: Could not read the data for this file {filepath}\")    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of partition for the Data: 27\n"
     ]
    }
   ],
   "source": [
    "if partition > 0:\n",
    "    arxiv_df = arxiv_df.repartition(partition)\n",
    "print(\"The number of partition for the Data:\",arxiv_df.rdd.getNumPartitions())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of executer in the cluster 12\n"
     ]
    }
   ],
   "source": [
    "executer = spark.conf.get(\"spark.executor.instances\")\n",
    "print(\"number of executer in the cluster:\",executer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "spark.yarn.dist.jars: file:///home/ubuntu/.ivy2/jars/io.delta_delta-core_2.12-2.3.0.jar,file:///home/ubuntu/.ivy2/jars/io.delta_delta-storage-2.3.0.jar,file:///home/ubuntu/.ivy2/jars/org.antlr_antlr4-runtime-4.8.jar\n",
      "spark.submit.pyFiles: /home/ubuntu/.ivy2/jars/io.delta_delta-core_2.12-2.3.0.jar,/home/ubuntu/.ivy2/jars/io.delta_delta-storage-2.3.0.jar,/home/ubuntu/.ivy2/jars/org.antlr_antlr4-runtime-4.8.jar\n",
      "spark.app.name: Arxiv_Classification\n",
      "spark.ui.proxyBase: /proxy/application_1679580022279_0108\n",
      "spark.jars.packages: io.delta:delta-core_2.12:2.3.0\n",
      "spark.master: yarn\n",
      "spark.sql.extensions: io.delta.sql.DeltaSparkSessionExtension\n",
      "spark.yarn.isPython: true\n",
      "spark.submit.deployMode: client\n",
      "spark.yarn.dist.pyFiles: file:///home/ubuntu/.ivy2/jars/io.delta_delta-core_2.12-2.3.0.jar,file:///home/ubuntu/.ivy2/jars/io.delta_delta-storage-2.3.0.jar,file:///home/ubuntu/.ivy2/jars/org.antlr_antlr4-runtime-4.8.jar\n",
      "spark.app.submitTime: 1682043419069\n",
      "spark.repl.local.jars: file:///home/ubuntu/.ivy2/jars/io.delta_delta-core_2.12-2.3.0.jar,file:///home/ubuntu/.ivy2/jars/io.delta_delta-storage-2.3.0.jar,file:///home/ubuntu/.ivy2/jars/org.antlr_antlr4-runtime-4.8.jar\n",
      "spark.ui.showConsoleProgress: true\n",
      "spark.sql.catalog.spark_catalog: org.apache.spark.sql.delta.catalog.DeltaCatalog\n"
     ]
    }
   ],
   "source": [
    "from pyspark import SparkConf\n",
    "\n",
    "conf = SparkConf()\n",
    "config_map = conf.getAll()\n",
    "for key, value in config_map:\n",
    "    print(f\"{key}: {value}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/04/18 16:05:41 WARN SparkSession: Using an existing Spark session; only runtime SQL configurations will take effect.\n",
      "Adaptive Query Execution is enabled\n"
     ]
    }
   ],
   "source": [
    "spark = SparkSession.builder.appName(\"MyApp\").getOrCreate()\n",
    "aqe_enabled = spark.conf.get(\"spark.sql.adaptive.enabled\")\n",
    "print(f\"Adaptive Query Execution is {'enabled' if aqe_enabled == 'true' else 'disabled'}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- id: string (nullable = true)\n",
      " |-- authors: string (nullable = true)\n",
      " |-- title: string (nullable = true)\n",
      " |-- abstract: string (nullable = true)\n",
      " |-- journal_ref: string (nullable = true)\n",
      " |-- category: string (nullable = true)\n",
      " |-- update_date: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# change the column names to the same name for the Arxiv metadata \n",
    "arxiv_df = arxiv_df.selectExpr(\"_c0 as id\", \"_c1 as authors\", \"_c2 as title\", \"_c3 as abstract\", \n",
    "                                \"_c4 as journal_ref\", \"_c5 as category\", \"_c6 as update_date\")\n",
    "\n",
    "arxiv_df.printSchema()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "arxiv_df = arxiv_df.withColumn(\"main_category\",\n",
    "                   when(split(arxiv_df.category, \"\\\\.\")[0] == \"cs\", \"computer science\")\n",
    "                   .when(split(arxiv_df.category, \"\\\\.\")[0] == \"math\", \"mathematics\")\n",
    "                   .when(split(arxiv_df.category, \"\\\\.\")[0] == \"econ\", \"economics\")\n",
    "                   .when(split(arxiv_df.category, \"\\\\.\")[0] == \"eess\", \"electrical engineering\")\n",
    "                   .when(split(arxiv_df.category, \"\\\\.\")[0] == \"q-bio\", \"quantitative biology\")\n",
    "                   .when(split(arxiv_df.category, \"\\\\.\")[0] == \"q-fin\", \"quantitative finance\")\n",
    "                   .when(split(arxiv_df.category, \"\\\\.\")[0] == \"stat\", \"statistics\")                   \n",
    "                   .otherwise(\"physics\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 1:>                                                          (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+--------------------------------------------------+----------------------------------------------------+---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+-----------+---------------+------------+----------------+\n",
      "|id        |authors                                           |title                                               |abstract                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                         |journal_ref|category       |update_date |main_category   |\n",
      "+----------+--------------------------------------------------+----------------------------------------------------+---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+-----------+---------------+------------+----------------+\n",
      "|2210.02280|Minoru Wakimoto                                   |Mock theta functions and indefinite modular forms II| In this paper, we compute the Zwegers's modification of the mock theta\\nfunctions $\\\\Phi^{[m,0] \\\\, \\\\ast}$ and study the modular transformation\\nproperties of the indefinite modular forms which appear in the explicit formula\\nfor the modified functions $\\\\tilde{\\\\Phi}^{[m,0] \\\\, \\\\ast}$.\\n                                                                                                                                                                                                                                                                                                                                                                                                                             |None       |math.NT math.RT|2022-10-11\\t|mathematics     |\n",
      "|2210.02281|P. Jameson Graber and Alp\\\\'ar R. M\\\\'esz\\\\'aros  |On monotonicity conditions for Mean Field Games     | In this paper we propose two new monotonicity conditions that could serve as\\nsufficient conditions for uniqueness of Nash equilibria in mean field games. In\\nthis study we aim for $unconditional\\\\ uniqueness$ that is independent of the\\nlength of the time horizon, the regularity of the starting distribution of the\\nagents, or the regularization effect of a non-degenerate idiosyncratic noise.\\nThrough a rich class of simple examples we show that these new conditions are\\nnot only in dichotomy with each other, but also with the two widely studied\\nmonotonicity conditions in the literature, the Lasry-Lions monotonicity and\\ndisplacement monotonicity conditions.\\n                                   |None       |math.AP math.OC|2022-10-06\\t|mathematics     |\n",
      "|2210.02282|Cornelia Ott, Hedongliang Liu, Antonia Wachter-Zeh|Covering Properties of Sum-Rank Metric Codes        | The sum-rank metric can be seen as a generalization of both, the rank and the\\nHamming metric. It is well known that sum-rank metric codes outperform rank\\nmetric codes in terms of the required field size to construct maximum distance\\nseparable codes (i.e., the codes achieving the Singleton bound in the\\ncorresponding metric). In this work, we investigate the covering property of\\nsum-rank metric codes to enrich the theory of sum-rank metric codes. We intend\\nto answer the question: what is the minimum cardinality of a code given a\\nsum-rank covering radius? We show the relations of this quantity between\\ndifferent metrics and provide several lower and upper bounds for sum-rank\\nmetric codes.\\n|None       |cs.IT math.IT  |2022-10-06\\t|computer science|\n",
      "+----------+--------------------------------------------------+----------------------------------------------------+---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+-----------+---------------+------------+----------------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "arxiv_df.show(3, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+----------------------------------------------------+---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+----------------+\n",
      "|id        |title                                               |abstract                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                         |main_category   |\n",
      "+----------+----------------------------------------------------+---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+----------------+\n",
      "|2210.02280|Mock theta functions and indefinite modular forms II| In this paper, we compute the Zwegers's modification of the mock theta\\nfunctions $\\\\Phi^{[m,0] \\\\, \\\\ast}$ and study the modular transformation\\nproperties of the indefinite modular forms which appear in the explicit formula\\nfor the modified functions $\\\\tilde{\\\\Phi}^{[m,0] \\\\, \\\\ast}$.\\n                                                                                                                                                                                                                                                                                                                                                                                                                             |mathematics     |\n",
      "|2210.02281|On monotonicity conditions for Mean Field Games     | In this paper we propose two new monotonicity conditions that could serve as\\nsufficient conditions for uniqueness of Nash equilibria in mean field games. In\\nthis study we aim for $unconditional\\\\ uniqueness$ that is independent of the\\nlength of the time horizon, the regularity of the starting distribution of the\\nagents, or the regularization effect of a non-degenerate idiosyncratic noise.\\nThrough a rich class of simple examples we show that these new conditions are\\nnot only in dichotomy with each other, but also with the two widely studied\\nmonotonicity conditions in the literature, the Lasry-Lions monotonicity and\\ndisplacement monotonicity conditions.\\n                                   |mathematics     |\n",
      "|2210.02282|Covering Properties of Sum-Rank Metric Codes        | The sum-rank metric can be seen as a generalization of both, the rank and the\\nHamming metric. It is well known that sum-rank metric codes outperform rank\\nmetric codes in terms of the required field size to construct maximum distance\\nseparable codes (i.e., the codes achieving the Singleton bound in the\\ncorresponding metric). In this work, we investigate the covering property of\\nsum-rank metric codes to enrich the theory of sum-rank metric codes. We intend\\nto answer the question: what is the minimum cardinality of a code given a\\nsum-rank covering radius? We show the relations of this quantity between\\ndifferent metrics and provide several lower and upper bounds for sum-rank\\nmetric codes.\\n|computer science|\n",
      "+----------+----------------------------------------------------+---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+----------------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# determine the columns that we used for machine learning model\n",
    "clean_arxiv_df = arxiv_df.select(\"id\", \"title\", \"abstract\", \"main_category\")\n",
    "\n",
    "clean_arxiv_df.show(3, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concatenate the title and abstract into a single column\n",
    "clean_arxiv_df = clean_arxiv_df.withColumn('text', concat_ws(' ', clean_arxiv_df['title'], clean_arxiv_df['abstract']))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = Create_ML_pipline()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "TrainingFile = '/Dat500_Group09/input/training'\n",
    "TestingFile = '/Dat500_Group09/input/testing'\n",
    "# Split the data into training and testing sets\n",
    "test_ratio = 0.2\n",
    "trainingData, testData = clean_arxiv_df.randomSplit([1-test_ratio, test_ratio], seed=24)\n",
    "# save Training Data into Delta table\n",
    "if not DeltaTable.isDeltaTable(spark, TrainingFile):\n",
    "    trainingData.write.format(\"delta\").save(TrainingFile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainingData, testData = clean_arxiv_df.randomSplit([1-test_ratio, test_ratio], seed=24)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====================================================================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Data size:  1763556\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 5:======================================================>  (26 + 1) / 27]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing Data size:  440363\n",
      "====================================================================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "if bprint == 1:\n",
    "    print(\"=\"*100)\n",
    "    print(\"Training Data size: \", trainingData.count())\n",
    "    print(\"Testing Data size: \", testData.count())\n",
    "    print(\"=\"*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/04/21 02:37:35 WARN DAGScheduler: Broadcasting large task binary with size 2.6 MiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 15:=====================================================>  (26 + 1) / 27]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/04/21 02:41:38 WARN DAGScheduler: Broadcasting large task binary with size 2.6 MiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/04/21 02:41:41 WARN DAGScheduler: Broadcasting large task binary with size 6.7 MiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 17:=====================================================>  (26 + 1) / 27]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/04/21 02:45:59 WARN DAGScheduler: Broadcasting large task binary with size 6.7 MiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/04/21 02:46:01 WARN DAGScheduler: Broadcasting large task binary with size 6.7 MiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 19:=====================================================>  (26 + 1) / 27]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/04/21 02:51:05 WARN DAGScheduler: Broadcasting large task binary with size 6.7 MiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/04/21 02:51:07 WARN InstanceBuilder$NativeBLAS: Failed to load implementation from:dev.ludovic.netlib.blas.JNIBLAS\n",
      "23/04/21 02:51:07 WARN InstanceBuilder$NativeBLAS: Failed to load implementation from:dev.ludovic.netlib.blas.ForeignLinkerBLAS\n",
      "23/04/21 02:51:07 WARN BLAS: Failed to load implementation from: com.github.fommil.netlib.NativeSystemBLAS\n",
      "23/04/21 02:51:07 WARN BLAS: Failed to load implementation from: com.github.fommil.netlib.NativeRefBLAS\n",
      "23/04/21 02:51:08 WARN DAGScheduler: Broadcasting large task binary with size 6.7 MiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 21:=====================================================>  (26 + 1) / 27]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/04/21 02:51:48 WARN DAGScheduler: Broadcasting large task binary with size 6.7 MiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/04/21 02:51:50 WARN DAGScheduler: Broadcasting large task binary with size 6.7 MiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 23:=====================================================>  (26 + 1) / 27]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/04/21 02:52:29 WARN DAGScheduler: Broadcasting large task binary with size 6.7 MiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/04/21 02:52:31 WARN DAGScheduler: Broadcasting large task binary with size 6.7 MiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 25:=====================================================>  (26 + 1) / 27]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/04/21 02:53:12 WARN DAGScheduler: Broadcasting large task binary with size 6.7 MiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/04/21 02:53:14 WARN DAGScheduler: Broadcasting large task binary with size 6.7 MiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 27:=====================================================>  (26 + 1) / 27]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/04/21 02:53:54 WARN DAGScheduler: Broadcasting large task binary with size 6.7 MiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/04/21 02:53:56 WARN DAGScheduler: Broadcasting large task binary with size 6.7 MiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 29:=====================================================>  (26 + 1) / 27]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/04/21 02:54:37 WARN DAGScheduler: Broadcasting large task binary with size 6.7 MiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/04/21 02:54:39 WARN DAGScheduler: Broadcasting large task binary with size 6.7 MiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 31:=====================================================>  (26 + 1) / 27]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/04/21 02:55:20 WARN DAGScheduler: Broadcasting large task binary with size 6.7 MiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/04/21 02:55:23 WARN DAGScheduler: Broadcasting large task binary with size 6.7 MiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 33:=====================================================>  (26 + 1) / 27]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/04/21 02:56:03 WARN DAGScheduler: Broadcasting large task binary with size 6.7 MiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/04/21 02:56:05 WARN DAGScheduler: Broadcasting large task binary with size 6.7 MiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 35:=====================================================>  (26 + 1) / 27]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/04/21 02:56:45 WARN DAGScheduler: Broadcasting large task binary with size 6.7 MiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/04/21 02:56:47 WARN DAGScheduler: Broadcasting large task binary with size 6.7 MiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 37:=====================================================>  (26 + 1) / 27]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/04/21 02:57:27 WARN DAGScheduler: Broadcasting large task binary with size 6.7 MiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/04/21 02:57:30 WARN DAGScheduler: Broadcasting large task binary with size 6.7 MiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 39:=====================================================>  (26 + 1) / 27]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/04/21 02:58:09 WARN DAGScheduler: Broadcasting large task binary with size 6.7 MiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/04/21 02:58:11 WARN DAGScheduler: Broadcasting large task binary with size 6.7 MiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 41:=====================================================>  (26 + 1) / 27]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/04/21 02:58:51 WARN DAGScheduler: Broadcasting large task binary with size 6.7 MiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/04/21 02:58:53 WARN DAGScheduler: Broadcasting large task binary with size 6.7 MiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 43:=====================================================>  (26 + 1) / 27]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/04/21 02:59:33 WARN DAGScheduler: Broadcasting large task binary with size 6.7 MiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/04/21 02:59:35 WARN DAGScheduler: Broadcasting large task binary with size 6.7 MiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 45:=====================================================>  (26 + 1) / 27]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/04/21 03:00:16 WARN DAGScheduler: Broadcasting large task binary with size 6.7 MiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/04/21 03:00:18 WARN DAGScheduler: Broadcasting large task binary with size 6.7 MiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 47:=====================================================>  (26 + 1) / 27]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/04/21 03:00:58 WARN DAGScheduler: Broadcasting large task binary with size 6.7 MiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/04/21 03:01:00 WARN DAGScheduler: Broadcasting large task binary with size 6.7 MiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 49:=====================================================>  (26 + 1) / 27]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/04/21 03:01:40 WARN DAGScheduler: Broadcasting large task binary with size 6.7 MiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/04/21 03:01:42 WARN DAGScheduler: Broadcasting large task binary with size 6.7 MiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 51:=====================================================>  (26 + 1) / 27]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/04/21 03:02:22 WARN DAGScheduler: Broadcasting large task binary with size 6.7 MiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/04/21 03:02:24 WARN BlockManager: Asked to remove block broadcast_76, which does not exist\n",
      "23/04/21 03:02:24 WARN DAGScheduler: Broadcasting large task binary with size 6.7 MiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 53:=====================================================>  (26 + 1) / 27]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/04/21 03:03:05 WARN DAGScheduler: Broadcasting large task binary with size 6.7 MiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/04/21 03:03:07 WARN DAGScheduler: Broadcasting large task binary with size 6.7 MiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 55:=====================================================>  (26 + 1) / 27]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/04/21 03:03:47 WARN DAGScheduler: Broadcasting large task binary with size 6.7 MiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/04/21 03:03:50 WARN DAGScheduler: Broadcasting large task binary with size 6.7 MiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 57:=====================================================>  (26 + 1) / 27]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/04/21 03:04:29 WARN DAGScheduler: Broadcasting large task binary with size 6.7 MiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/04/21 03:04:31 WARN DAGScheduler: Broadcasting large task binary with size 6.7 MiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 59:=====================================================>  (26 + 1) / 27]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/04/21 03:05:11 WARN DAGScheduler: Broadcasting large task binary with size 6.7 MiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/04/21 03:05:13 WARN DAGScheduler: Broadcasting large task binary with size 6.7 MiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 61:=====================================================>  (26 + 1) / 27]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/04/21 03:05:53 WARN DAGScheduler: Broadcasting large task binary with size 6.7 MiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/04/21 03:05:55 WARN DAGScheduler: Broadcasting large task binary with size 6.7 MiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 64:>                                                         (0 + 2) / 4]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/04/21 03:06:35 WARN DAGScheduler: Broadcasting large task binary with size 6.7 MiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/04/21 03:06:37 WARN DAGScheduler: Broadcasting large task binary with size 6.7 MiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 65:=====================================================>  (26 + 1) / 27]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/04/21 03:07:16 WARN DAGScheduler: Broadcasting large task binary with size 6.7 MiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/04/21 03:07:19 WARN DAGScheduler: Broadcasting large task binary with size 6.7 MiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 67:=====================================================>  (26 + 1) / 27]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/04/21 03:07:59 WARN DAGScheduler: Broadcasting large task binary with size 6.7 MiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/04/21 03:08:01 WARN DAGScheduler: Broadcasting large task binary with size 6.7 MiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 69:=====================================================>  (26 + 1) / 27]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/04/21 03:08:42 WARN DAGScheduler: Broadcasting large task binary with size 6.7 MiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/04/21 03:08:44 WARN DAGScheduler: Broadcasting large task binary with size 6.7 MiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 71:=====================================================>  (26 + 1) / 27]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/04/21 03:09:23 WARN DAGScheduler: Broadcasting large task binary with size 6.7 MiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/04/21 03:09:26 WARN DAGScheduler: Broadcasting large task binary with size 6.7 MiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 73:=====================================================>  (26 + 1) / 27]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/04/21 03:10:06 WARN DAGScheduler: Broadcasting large task binary with size 6.7 MiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/04/21 03:10:09 WARN DAGScheduler: Broadcasting large task binary with size 6.7 MiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 75:=====================================================>  (26 + 1) / 27]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/04/21 03:10:48 WARN DAGScheduler: Broadcasting large task binary with size 6.7 MiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/04/21 03:10:51 WARN DAGScheduler: Broadcasting large task binary with size 6.7 MiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 77:=====================================================>  (26 + 1) / 27]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/04/21 03:11:30 WARN DAGScheduler: Broadcasting large task binary with size 6.7 MiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/04/21 03:11:33 WARN DAGScheduler: Broadcasting large task binary with size 6.7 MiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 79:=====================================================>  (26 + 1) / 27]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/04/21 03:12:13 WARN DAGScheduler: Broadcasting large task binary with size 6.7 MiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/04/21 03:12:15 WARN DAGScheduler: Broadcasting large task binary with size 6.7 MiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 81:=====================================================>  (26 + 1) / 27]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/04/21 03:12:54 WARN DAGScheduler: Broadcasting large task binary with size 6.7 MiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/04/21 03:12:57 WARN DAGScheduler: Broadcasting large task binary with size 6.7 MiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 83:=====================================================>  (26 + 1) / 27]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/04/21 03:13:37 WARN DAGScheduler: Broadcasting large task binary with size 6.7 MiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/04/21 03:13:39 WARN DAGScheduler: Broadcasting large task binary with size 6.7 MiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 85:=====================================================>  (26 + 1) / 27]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/04/21 03:14:19 WARN DAGScheduler: Broadcasting large task binary with size 6.7 MiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/04/21 03:14:21 WARN DAGScheduler: Broadcasting large task binary with size 6.7 MiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 88:>                                                         (0 + 2) / 4]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/04/21 03:15:01 WARN DAGScheduler: Broadcasting large task binary with size 6.7 MiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/04/21 03:15:03 WARN DAGScheduler: Broadcasting large task binary with size 6.7 MiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 89:=====================================================>  (26 + 1) / 27]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/04/21 03:15:43 WARN DAGScheduler: Broadcasting large task binary with size 6.7 MiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/04/21 03:15:45 WARN DAGScheduler: Broadcasting large task binary with size 6.7 MiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 91:=====================================================>  (26 + 1) / 27]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/04/21 03:16:25 WARN DAGScheduler: Broadcasting large task binary with size 6.7 MiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/04/21 03:16:27 WARN DAGScheduler: Broadcasting large task binary with size 6.7 MiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 93:=====================================================>  (26 + 1) / 27]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/04/21 03:17:06 WARN DAGScheduler: Broadcasting large task binary with size 6.7 MiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/04/21 03:17:08 WARN DAGScheduler: Broadcasting large task binary with size 6.7 MiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 95:=====================================================>  (26 + 1) / 27]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/04/21 03:17:48 WARN DAGScheduler: Broadcasting large task binary with size 6.7 MiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/04/21 03:17:50 WARN DAGScheduler: Broadcasting large task binary with size 6.7 MiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 97:=====================================================>  (26 + 1) / 27]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/04/21 03:18:30 WARN DAGScheduler: Broadcasting large task binary with size 6.7 MiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/04/21 03:18:32 WARN DAGScheduler: Broadcasting large task binary with size 6.7 MiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 99:=====================================================>  (26 + 1) / 27]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/04/21 03:19:11 WARN DAGScheduler: Broadcasting large task binary with size 6.7 MiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/04/21 03:19:13 WARN DAGScheduler: Broadcasting large task binary with size 6.7 MiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 101:====================================================>  (26 + 1) / 27]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/04/21 03:19:53 WARN DAGScheduler: Broadcasting large task binary with size 6.7 MiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/04/21 03:19:56 WARN DAGScheduler: Broadcasting large task binary with size 6.7 MiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 103:====================================================>  (26 + 1) / 27]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/04/21 03:20:35 WARN DAGScheduler: Broadcasting large task binary with size 6.7 MiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/04/21 03:20:38 WARN DAGScheduler: Broadcasting large task binary with size 6.7 MiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 105:====================================================>  (26 + 1) / 27]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/04/21 03:21:17 WARN DAGScheduler: Broadcasting large task binary with size 6.7 MiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/04/21 03:21:19 WARN DAGScheduler: Broadcasting large task binary with size 6.7 MiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 108:>                                                        (0 + 2) / 4]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/04/21 03:22:00 WARN DAGScheduler: Broadcasting large task binary with size 6.7 MiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/04/21 03:22:02 WARN DAGScheduler: Broadcasting large task binary with size 6.7 MiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 109:====================================================>  (26 + 1) / 27]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/04/21 03:22:41 WARN DAGScheduler: Broadcasting large task binary with size 6.7 MiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/04/21 03:22:44 WARN DAGScheduler: Broadcasting large task binary with size 6.7 MiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 111:====================================================>  (26 + 1) / 27]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/04/21 03:23:24 WARN DAGScheduler: Broadcasting large task binary with size 6.7 MiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/04/21 03:23:26 WARN DAGScheduler: Broadcasting large task binary with size 6.7 MiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 114:>                                                        (0 + 2) / 4]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/04/21 03:24:06 WARN DAGScheduler: Broadcasting large task binary with size 6.7 MiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/04/21 03:24:09 WARN DAGScheduler: Broadcasting large task binary with size 6.7 MiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 115:====================================================>  (26 + 1) / 27]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/04/21 03:24:48 WARN DAGScheduler: Broadcasting large task binary with size 6.7 MiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/04/21 03:24:51 WARN DAGScheduler: Broadcasting large task binary with size 6.7 MiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 117:====================================================>  (26 + 1) / 27]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/04/21 03:25:31 WARN DAGScheduler: Broadcasting large task binary with size 6.7 MiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/04/21 03:25:33 WARN DAGScheduler: Broadcasting large task binary with size 6.7 MiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 119:====================================================>  (26 + 1) / 27]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/04/21 03:26:13 WARN DAGScheduler: Broadcasting large task binary with size 6.7 MiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/04/21 03:26:15 WARN DAGScheduler: Broadcasting large task binary with size 6.7 MiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 121:====================================================>  (26 + 1) / 27]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/04/21 03:26:55 WARN DAGScheduler: Broadcasting large task binary with size 6.7 MiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/04/21 03:26:57 WARN DAGScheduler: Broadcasting large task binary with size 6.7 MiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 124:>                                                        (0 + 2) / 4]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/04/21 03:27:37 WARN DAGScheduler: Broadcasting large task binary with size 6.7 MiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/04/21 03:27:39 WARN DAGScheduler: Broadcasting large task binary with size 6.7 MiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 125:====================================================>  (26 + 1) / 27]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/04/21 03:28:19 WARN DAGScheduler: Broadcasting large task binary with size 6.7 MiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/04/21 03:28:21 WARN DAGScheduler: Broadcasting large task binary with size 6.7 MiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 127:====================================================>  (26 + 1) / 27]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/04/21 03:29:01 WARN DAGScheduler: Broadcasting large task binary with size 6.7 MiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/04/21 03:29:03 WARN DAGScheduler: Broadcasting large task binary with size 6.7 MiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 129:====================================================>  (26 + 1) / 27]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/04/21 03:29:43 WARN DAGScheduler: Broadcasting large task binary with size 6.7 MiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/04/21 03:29:46 WARN DAGScheduler: Broadcasting large task binary with size 6.7 MiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 131:====================================================>  (26 + 1) / 27]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/04/21 03:30:25 WARN DAGScheduler: Broadcasting large task binary with size 6.7 MiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/04/21 03:30:28 WARN DAGScheduler: Broadcasting large task binary with size 6.7 MiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 133:====================================================>  (26 + 1) / 27]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/04/21 03:31:08 WARN DAGScheduler: Broadcasting large task binary with size 6.7 MiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/04/21 03:31:10 WARN DAGScheduler: Broadcasting large task binary with size 6.7 MiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 135:====================================================>  (26 + 1) / 27]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/04/21 03:31:49 WARN DAGScheduler: Broadcasting large task binary with size 6.7 MiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/04/21 03:31:52 WARN DAGScheduler: Broadcasting large task binary with size 6.7 MiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 137:====================================================>  (26 + 1) / 27]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/04/21 03:32:31 WARN DAGScheduler: Broadcasting large task binary with size 6.7 MiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/04/21 03:32:34 WARN DAGScheduler: Broadcasting large task binary with size 6.7 MiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 139:====================================================>  (26 + 1) / 27]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/04/21 03:33:14 WARN DAGScheduler: Broadcasting large task binary with size 6.7 MiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/04/21 03:33:16 WARN DAGScheduler: Broadcasting large task binary with size 6.7 MiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 141:====================================================>  (26 + 1) / 27]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/04/21 03:33:56 WARN DAGScheduler: Broadcasting large task binary with size 6.7 MiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/04/21 03:33:59 WARN DAGScheduler: Broadcasting large task binary with size 6.7 MiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 143:====================================================>  (26 + 1) / 27]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/04/21 03:34:38 WARN DAGScheduler: Broadcasting large task binary with size 6.7 MiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/04/21 03:34:42 WARN DAGScheduler: Broadcasting large task binary with size 6.7 MiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 145:====================================================>  (26 + 1) / 27]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/04/21 03:35:21 WARN DAGScheduler: Broadcasting large task binary with size 6.7 MiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/04/21 03:35:23 WARN BlockManager: Asked to remove block broadcast_217_piece3, which does not exist\n",
      "23/04/21 03:35:24 WARN DAGScheduler: Broadcasting large task binary with size 6.7 MiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 148:>                                                        (0 + 2) / 4]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/04/21 03:36:04 WARN DAGScheduler: Broadcasting large task binary with size 6.7 MiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/04/21 03:36:06 WARN DAGScheduler: Broadcasting large task binary with size 6.7 MiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 149:====================================================>  (26 + 1) / 27]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/04/21 03:36:46 WARN DAGScheduler: Broadcasting large task binary with size 6.7 MiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/04/21 03:36:48 WARN DAGScheduler: Broadcasting large task binary with size 6.7 MiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 152:>                                                        (0 + 0) / 4]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/04/21 03:37:29 WARN DAGScheduler: Broadcasting large task binary with size 6.7 MiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/04/21 03:37:31 WARN DAGScheduler: Broadcasting large task binary with size 6.7 MiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 153:====================================================>  (26 + 1) / 27]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/04/21 03:38:10 WARN DAGScheduler: Broadcasting large task binary with size 6.7 MiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/04/21 03:38:13 WARN DAGScheduler: Broadcasting large task binary with size 6.7 MiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 155:====================================================>  (26 + 1) / 27]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/04/21 03:38:52 WARN DAGScheduler: Broadcasting large task binary with size 6.7 MiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/04/21 03:38:54 WARN DAGScheduler: Broadcasting large task binary with size 6.7 MiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 157:====================================================>  (26 + 1) / 27]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/04/21 03:39:34 WARN DAGScheduler: Broadcasting large task binary with size 6.7 MiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/04/21 03:39:37 WARN DAGScheduler: Broadcasting large task binary with size 6.7 MiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 159:====================================================>  (26 + 1) / 27]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/04/21 03:40:16 WARN DAGScheduler: Broadcasting large task binary with size 6.7 MiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/04/21 03:40:19 WARN DAGScheduler: Broadcasting large task binary with size 6.7 MiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 161:====================================================>  (26 + 1) / 27]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/04/21 03:40:58 WARN DAGScheduler: Broadcasting large task binary with size 6.7 MiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/04/21 03:41:01 WARN DAGScheduler: Broadcasting large task binary with size 6.7 MiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 163:====================================================>  (26 + 1) / 27]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/04/21 03:41:41 WARN DAGScheduler: Broadcasting large task binary with size 6.7 MiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/04/21 03:41:43 WARN DAGScheduler: Broadcasting large task binary with size 6.7 MiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 166:>                                                        (0 + 2) / 4]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/04/21 03:42:23 WARN DAGScheduler: Broadcasting large task binary with size 6.7 MiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/04/21 03:42:26 WARN DAGScheduler: Broadcasting large task binary with size 6.7 MiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 167:====================================================>  (26 + 1) / 27]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/04/21 03:43:05 WARN DAGScheduler: Broadcasting large task binary with size 6.7 MiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/04/21 03:43:07 WARN DAGScheduler: Broadcasting large task binary with size 6.7 MiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 169:====================================================>  (26 + 1) / 27]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/04/21 03:43:47 WARN DAGScheduler: Broadcasting large task binary with size 6.7 MiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/04/21 03:43:49 WARN DAGScheduler: Broadcasting large task binary with size 6.7 MiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 171:====================================================>  (26 + 1) / 27]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/04/21 03:44:28 WARN DAGScheduler: Broadcasting large task binary with size 6.7 MiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/04/21 03:44:32 WARN DAGScheduler: Broadcasting large task binary with size 6.7 MiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 173:====================================================>  (26 + 1) / 27]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/04/21 03:45:12 WARN DAGScheduler: Broadcasting large task binary with size 6.7 MiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/04/21 03:45:14 WARN DAGScheduler: Broadcasting large task binary with size 6.7 MiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 175:====================================================>  (26 + 1) / 27]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/04/21 03:45:53 WARN DAGScheduler: Broadcasting large task binary with size 6.7 MiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/04/21 03:45:55 WARN DAGScheduler: Broadcasting large task binary with size 6.7 MiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 177:====================================================>  (26 + 1) / 27]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/04/21 03:46:35 WARN DAGScheduler: Broadcasting large task binary with size 6.7 MiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/04/21 03:46:38 WARN DAGScheduler: Broadcasting large task binary with size 6.7 MiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 179:====================================================>  (26 + 1) / 27]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/04/21 03:47:18 WARN DAGScheduler: Broadcasting large task binary with size 6.7 MiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/04/21 03:47:20 WARN DAGScheduler: Broadcasting large task binary with size 6.7 MiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 181:====================================================>  (26 + 1) / 27]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/04/21 03:48:00 WARN DAGScheduler: Broadcasting large task binary with size 6.7 MiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/04/21 03:48:02 WARN DAGScheduler: Broadcasting large task binary with size 6.7 MiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 184:>                                                        (0 + 2) / 4]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/04/21 03:48:42 WARN DAGScheduler: Broadcasting large task binary with size 6.7 MiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/04/21 03:48:44 WARN DAGScheduler: Broadcasting large task binary with size 6.7 MiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 185:====================================================>  (26 + 1) / 27]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/04/21 03:49:24 WARN DAGScheduler: Broadcasting large task binary with size 6.7 MiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/04/21 03:49:27 WARN DAGScheduler: Broadcasting large task binary with size 6.7 MiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 187:====================================================>  (26 + 1) / 27]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/04/21 03:50:06 WARN DAGScheduler: Broadcasting large task binary with size 6.7 MiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/04/21 03:50:08 WARN DAGScheduler: Broadcasting large task binary with size 6.7 MiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 189:====================================================>  (26 + 1) / 27]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/04/21 03:50:47 WARN DAGScheduler: Broadcasting large task binary with size 6.7 MiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/04/21 03:50:50 WARN DAGScheduler: Broadcasting large task binary with size 6.7 MiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 191:====================================================>  (26 + 1) / 27]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/04/21 03:51:30 WARN DAGScheduler: Broadcasting large task binary with size 6.7 MiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/04/21 03:51:32 WARN DAGScheduler: Broadcasting large task binary with size 6.7 MiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 193:====================================================>  (26 + 1) / 27]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/04/21 03:52:11 WARN DAGScheduler: Broadcasting large task binary with size 6.7 MiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/04/21 03:52:14 WARN DAGScheduler: Broadcasting large task binary with size 6.7 MiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 196:>                                                        (0 + 2) / 4]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/04/21 03:52:54 WARN DAGScheduler: Broadcasting large task binary with size 6.7 MiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/04/21 03:52:56 WARN DAGScheduler: Broadcasting large task binary with size 6.7 MiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 197:====================================================>  (26 + 1) / 27]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/04/21 03:53:36 WARN DAGScheduler: Broadcasting large task binary with size 6.7 MiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/04/21 03:53:38 WARN DAGScheduler: Broadcasting large task binary with size 6.7 MiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 199:====================================================>  (26 + 1) / 27]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/04/21 03:54:17 WARN DAGScheduler: Broadcasting large task binary with size 6.7 MiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/04/21 03:54:19 WARN DAGScheduler: Broadcasting large task binary with size 6.7 MiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 201:====================================================>  (26 + 1) / 27]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/04/21 03:54:59 WARN DAGScheduler: Broadcasting large task binary with size 6.7 MiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/04/21 03:55:02 WARN DAGScheduler: Broadcasting large task binary with size 6.7 MiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 203:====================================================>  (26 + 1) / 27]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/04/21 03:55:41 WARN DAGScheduler: Broadcasting large task binary with size 6.7 MiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/04/21 03:55:44 WARN DAGScheduler: Broadcasting large task binary with size 6.7 MiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 206:>                                                        (0 + 2) / 4]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/04/21 03:56:23 WARN DAGScheduler: Broadcasting large task binary with size 6.7 MiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/04/21 03:56:26 WARN DAGScheduler: Broadcasting large task binary with size 6.7 MiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 207:====================================================>  (26 + 1) / 27]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/04/21 03:57:05 WARN DAGScheduler: Broadcasting large task binary with size 6.7 MiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/04/21 03:57:08 WARN DAGScheduler: Broadcasting large task binary with size 6.7 MiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 210:>                                                        (0 + 2) / 4]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/04/21 03:57:48 WARN DAGScheduler: Broadcasting large task binary with size 6.7 MiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/04/21 03:57:51 WARN DAGScheduler: Broadcasting large task binary with size 6.7 MiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 211:====================================================>  (26 + 1) / 27]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/04/21 03:58:31 WARN DAGScheduler: Broadcasting large task binary with size 6.7 MiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/04/21 03:58:33 WARN DAGScheduler: Broadcasting large task binary with size 6.7 MiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 213:====================================================>  (26 + 1) / 27]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/04/21 03:59:12 WARN DAGScheduler: Broadcasting large task binary with size 6.7 MiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/04/21 03:59:15 WARN DAGScheduler: Broadcasting large task binary with size 6.7 MiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 215:====================================================>  (26 + 1) / 27]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/04/21 03:59:55 WARN DAGScheduler: Broadcasting large task binary with size 6.7 MiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/04/21 03:59:57 WARN DAGScheduler: Broadcasting large task binary with size 6.7 MiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 217:====================================================>  (26 + 1) / 27]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/04/21 04:00:37 WARN DAGScheduler: Broadcasting large task binary with size 6.7 MiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/04/21 04:00:39 WARN DAGScheduler: Broadcasting large task binary with size 6.7 MiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 220:>                                                        (0 + 2) / 4]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/04/21 04:01:19 WARN DAGScheduler: Broadcasting large task binary with size 6.7 MiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# Fit the model\n",
    "ML_model = pipeline.fit(trainingData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/04/21 04:13:20 WARN TaskSetManager: Stage 229 contains a task of very large size (4849 KiB). The maximum recommended task size is 1000 KiB.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/04/21 04:13:22 WARN TaskSetManager: Stage 233 contains a task of very large size (4184 KiB). The maximum recommended task size is 1000 KiB.\n",
      "23/04/21 04:13:23 WARN TaskSetManager: Stage 237 contains a task of very large size (16725 KiB). The maximum recommended task size is 1000 KiB.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# save the machine learning model\n",
    "pipelinePath = 'hdfs:///Dat500_Group09/result/ML_model'\n",
    "ML_model.write().overwrite().save(pipelinePath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the saved machine learning model\n",
    "#from pyspark.ml import PipelineModel\n",
    "#savedPipelineModel = PipelineModel.load(pipelinePath)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make predictions on the testing data\n",
    "df_Prediction = ML_model.transform(testData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/04/21 04:17:30 WARN DAGScheduler: Broadcasting large task binary with size 22.7 MiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 240:>                                                        (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+----------------+-----+----------+\n",
      "|        id|   main_category|label|prediction|\n",
      "+----------+----------------+-----+----------+\n",
      "|2210.02287|computer science|  2.0|       2.0|\n",
      "|2210.02293|         physics|  0.0|       0.0|\n",
      "|2210.02298|         physics|  0.0|       5.0|\n",
      "+----------+----------------+-----+----------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# Print the dataframe with the original main_category and the predicted one\n",
    "df_Prediction = df_Prediction.select(\"id\", \"main_category\", \"label\", \"prediction\")\n",
    "df_Prediction.show(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/04/21 04:17:52 WARN DAGScheduler: Broadcasting large task binary with size 22.7 MiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 241:====================================================>  (26 + 1) / 27]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy = 0.857801\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# Evaluate the model using the F1 score\n",
    "evaluator = MulticlassClassificationEvaluator(labelCol=\"label\", predictionCol=\"prediction\", metricName=\"accuracy\")\n",
    "accuracy = evaluator.evaluate(df_Prediction)\n",
    "print(\"accuracy = %g\" % accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/04/18 16:34:43 WARN DAGScheduler: Broadcasting large task binary with size 22.7 MiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 47:=====================================================>  (26 + 1) / 27]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy = 0.848034\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# Evaluate the performance of the model\n",
    "evaluator = MulticlassClassificationEvaluator(labelCol=\"label\", predictionCol=\"prediction\", metricName=\"accuracy\")\n",
    "accuracy = evaluator.evaluate(df_Prediction)\n",
    "print(\"Accuracy = %g\" % accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Create delta table first time\n",
      "23/04/21 04:24:54 WARN DAGScheduler: Broadcasting large task binary with size 23.0 MiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/04/21 04:26:31 WARN package: Truncated the string representation of a plan since it was too large. This behavior can be adjusted by setting 'spark.sql.debug.maxToStringFields'.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# check if the Delta table exists  \n",
    "# DeltaTable.isDeltaTable(spark, \"spark-warehouse/table1\") # True \n",
    "#DeltaTable\n",
    "if DeltaTable.isDeltaTable(spark, delta_table_path):\n",
    "    print(\"update delta table\")\n",
    "    deltaTable = DeltaTable.forPath(spark, delta_table_path)\n",
    "    #\"target.id = updates.id and target.main_category = updates.main_category\") \\\n",
    "    deltaTable.alias(\"target\") \\\n",
    "        .merge(\n",
    "        source = df_Prediction.alias(\"updates\"),\n",
    "        condition = \"target.id = updates.id\") \\\n",
    "        .whenMatchedUpdate( set = \n",
    "        {\n",
    "            \"label\": \"updates.label\",\n",
    "            \"prediction\": \"updates.prediction\"     \n",
    "        }) \\\n",
    "        .whenNotMatchedInsert(values =\n",
    "        {\n",
    "            \"id\": \"updates.id\",\n",
    "            \"main_category\": \"updates.main_category\",\n",
    "            \"label\": \"updates.label\",\n",
    "            \"prediction\": \"updates.prediction\"        \n",
    "        }) \\\n",
    "        .execute()\n",
    "else: # file not exists\n",
    "    print(\"Create delta table first time\")\n",
    "    df_Prediction.write.format(\"delta\").save(delta_table_path)\n",
    "    #df_Prediction.write.format(\"delta\").partitionBy(\"main_category\").save(delta_table_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+----------------+-----+----------+\n",
      "|        id|   main_category|label|prediction|\n",
      "+----------+----------------+-----+----------+\n",
      "|1710.08686|         physics|  0.0|       0.0|\n",
      "|1710.08690|         physics|  0.0|       0.0|\n",
      "|1710.08696|         physics|  0.0|       0.0|\n",
      "|1710.08697|     mathematics|  1.0|       1.0|\n",
      "|1710.08709|         physics|  0.0|       0.0|\n",
      "|1710.08710|         physics|  0.0|       0.0|\n",
      "|1710.08718|         physics|  0.0|       0.0|\n",
      "|1710.08721|computer science|  2.0|       4.0|\n",
      "|1710.08722|     mathematics|  1.0|       1.0|\n",
      "|1710.08724|     mathematics|  1.0|       1.0|\n",
      "+----------+----------------+-----+----------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df = spark.read.format(\"delta\").load(delta_table_path)\n",
    "df.show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "440363"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "880472"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.count()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
