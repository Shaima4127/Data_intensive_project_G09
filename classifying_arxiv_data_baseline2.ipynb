{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import pyspark\n",
    "import time\n",
    "from pyspark.sql import SparkSession \n",
    "from pyspark.sql.functions import *\n",
    "from pyspark.sql.types import *\n",
    "from pyspark.sql.functions import col, split, when, count\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.classification import LogisticRegression, RandomForestClassifier, LinearSVC, NaiveBayes\n",
    "from pyspark.ml.feature import HashingTF, Tokenizer\n",
    "from pyspark.ml.feature import StringIndexer, RegexTokenizer, StopWordsRemover, CountVectorizer, IDF\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "from pyspark.sql.functions import concat_ws\n",
    "from delta import DeltaTable, configure_spark_with_delta_pip\n",
    "\n",
    "partition = 0\n",
    "test_ratio = 0.2\n",
    "bprint = 1\n",
    "filepath = 'hdfs:///Dat500_Group09/input/output_meta/part*'\n",
    "# set the path to the Delta table\n",
    "delta_table_path = \"hdfs:///Dat500_Group09/spark_result/final_result/arxiv_meta\"\n",
    "\n",
    "\n",
    "#filepath = 'hdfs:///Dat500_Group09/output_meta/part*'\n",
    "#delta_table_path = \"hdfs:///Dat500_Group09/result/arxiv_sample\"    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Create_ML_pipline(ML_model = \"LR\"):\n",
    "  # Convert the main_category column to numeric using StringIndexer\n",
    "  labelIndexer = StringIndexer(inputCol=\"main_category\", outputCol=\"label\")\n",
    "\n",
    "  # Define the regular expression tokenizer\n",
    "  regexTokenizer = RegexTokenizer(inputCol=\"text\", outputCol=\"tokens\", pattern=\"\\\\W\")\n",
    "\n",
    "  # Define the stop words remover\n",
    "  stopWordsRemover = StopWordsRemover(inputCol=\"tokens\", outputCol=\"filtered_tokens\")\n",
    "\n",
    "  # Define the TF-IDF Vectorizer\n",
    "  countVectorizer = CountVectorizer(inputCol=\"filtered_tokens\", outputCol=\"vectorize_features\")\n",
    "  # hashingTF = HashingTF(inputCol=\"words\", outputCol=\"rawFeatures\", numFeatures=20)\n",
    "  idf = IDF(inputCol=\"vectorize_features\", outputCol=\"features\")\n",
    "\n",
    "  if ML_model == 'LR': # Create logistic regression classifier     \n",
    "    ML_Model = LogisticRegression(featuresCol=\"features\", labelCol=\"label\", maxIter=100)\n",
    "  elif ML_model == 'RF': # Create a Random Forest classifier\n",
    "    ML_Model = RandomForestClassifier(numTrees=500, maxDepth=5, labelCol=\"label\", featuresCol=\"features\")\n",
    "  elif ML_model == 'NB': # Create a Naive Bayes classifier\n",
    "    ML_Model = NaiveBayes(modelType=\"multinomial\", labelCol=\"label\", featuresCol=\"features\")\n",
    "\n",
    "  # Define the Pipeline\n",
    "  pipeline = Pipeline(stages=[labelIndexer, regexTokenizer, stopWordsRemover, countVectorizer, idf, ML_Model])\n",
    "\n",
    "  return pipeline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/04/22 10:17:37 WARN Client: Neither spark.yarn.jars nor spark.yarn.archive is set, falling back to uploading libraries under SPARK_HOME.\n",
      "23/04/22 10:17:45 WARN Client: Same path resource file:///home/ubuntu/.ivy2/jars/io.delta_delta-core_2.12-2.3.0.jar added multiple times to distributed cache.\n",
      "23/04/22 10:17:45 WARN Client: Same path resource file:///home/ubuntu/.ivy2/jars/io.delta_delta-storage-2.3.0.jar added multiple times to distributed cache.\n",
      "23/04/22 10:17:45 WARN Client: Same path resource file:///home/ubuntu/.ivy2/jars/org.antlr_antlr4-runtime-4.8.jar added multiple times to distributed cache.\n"
     ]
    }
   ],
   "source": [
    "  # Set the configuration properties for Delta tables\n",
    "builder = pyspark.sql.SparkSession.builder.appName(\"Arxiv_Classification\") \\\n",
    "    .master('yarn') \\\n",
    "    .config(\"spark.sql.extensions\", \"io.delta.sql.DeltaSparkSessionExtension\") \\\n",
    "    .config(\"spark.sql.catalog.spark_catalog\", \"org.apache.spark.sql.delta.catalog.DeltaCatalog\")\\\n",
    "    .config('spark.executor.instances', '8') \\\n",
    "    .config(\"spark.executor.memory\", \"2g\")\n",
    "    #.config(\"spark.sql.shuffle.partitions\", \"32\")\n",
    "    #.config('spark.driver.memory', '4g')\n",
    "    #.config(\"spark.databricks.delta.properties.defaults.autoOptimize.optimizeWrite\", \"true\")\\\n",
    "    #.config(\"spark.databricks.delta.properties.defaults.autoOptimize.autoCompact\", \"true\")\\    \n",
    "        #.config('spark.driver.maxResultSize', '4g') \\\n",
    "    #.config('spark.executor.instances', '12') \\\n",
    "    #.config(\"spark.executor.memory\", \"1g\") \\\n",
    "    #.config(\"spark.sql.shuffle.partitions\", \"200\").config('spark.driver.memory', '4g') \\\n",
    "# Set the delta.targetFileSize configuration\n",
    "#104857600   = 100MB\n",
    "#134217728   = 128MB\n",
    "#268435456 = 256 for 1TB data\n",
    "#spark.conf.set(\"delta.targetFileSize\", \"128MB\")\n",
    "\n",
    "\n",
    "spark = configure_spark_with_delta_pip(builder).getOrCreate()  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create the schema for our dataset to determine the datatype for each columns)\n",
    "dbschema = StructType([\n",
    "    StructField(\"id\", StringType(), True),\n",
    "    StructField(\"authors\", StringType(), True),\n",
    "    StructField(\"title\", StringType(), True),\n",
    "    StructField(\"abstract\", StringType(), True),\n",
    "    StructField(\"journal_ref\", StringType(), True),\n",
    "    StructField(\"category\", StringType(), True),\n",
    "    StructField(\"update_date\", StringType(), True),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# import csv file for the data\n",
    "try:\n",
    "  arxiv_df =spark.read.options(delimiter=\"::\", header=False, schema=dbschema).csv(filepath)    \n",
    "except:\n",
    "    print(f\"Error: Could not read the data for this file {filepath}\")    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- id: string (nullable = true)\n",
      " |-- authors: string (nullable = true)\n",
      " |-- title: string (nullable = true)\n",
      " |-- abstract: string (nullable = true)\n",
      " |-- journal_ref: string (nullable = true)\n",
      " |-- category: string (nullable = true)\n",
      " |-- update_date: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# change the column names to the same name for the Arxiv metadata \n",
    "arxiv_df = arxiv_df.selectExpr(\"_c0 as id\", \"_c1 as authors\", \"_c2 as title\", \"_c3 as abstract\", \n",
    "                                \"_c4 as journal_ref\", \"_c5 as category\", \"_c6 as update_date\")\n",
    "\n",
    "arxiv_df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[id: string, authors: string, title: string, abstract: string, journal_ref: string, category: string, update_date: string]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# try this later\n",
    "arxiv_df.cache() #Cache the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of partition for the Data: 27\n"
     ]
    }
   ],
   "source": [
    "if partition > 0:\n",
    "    arxiv_df = arxiv_df.repartition(partition)\n",
    "print(\"The number of partition for the Data:\",arxiv_df.rdd.getNumPartitions())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of executer in the cluster: 8\n",
      "the No of shuffle.partitions 200\n",
      "spark.executor.memory 2g\n"
     ]
    }
   ],
   "source": [
    "executer = spark.conf.get(\"spark.executor.instances\")\n",
    "print(\"number of executer in the cluster:\",executer)\n",
    "\n",
    "print(\"the No of shuffle.partitions\",  spark.conf.get(\"spark.sql.shuffle.partitions\"))\n",
    "#print('spark.driver.maxResultSize', spark.conf.get(\"spark.driver.maxResultSize\"))\n",
    "print(\"spark.executor.memory\",  spark.conf.get(\"spark.executor.memory\"))\n",
    "#print(\"spark.driver.memory\",  spark.conf.get(\"spark.driver.memory\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "spark.executor.memory: 2g\n",
      "spark.yarn.dist.jars: file:///home/ubuntu/.ivy2/jars/io.delta_delta-core_2.12-2.3.0.jar,file:///home/ubuntu/.ivy2/jars/io.delta_delta-storage-2.3.0.jar,file:///home/ubuntu/.ivy2/jars/org.antlr_antlr4-runtime-4.8.jar\n",
      "spark.submit.pyFiles: /home/ubuntu/.ivy2/jars/io.delta_delta-core_2.12-2.3.0.jar,/home/ubuntu/.ivy2/jars/io.delta_delta-storage-2.3.0.jar,/home/ubuntu/.ivy2/jars/org.antlr_antlr4-runtime-4.8.jar\n",
      "spark.app.name: Arxiv_Classification\n",
      "spark.executor.instances: 8\n",
      "spark.jars.packages: io.delta:delta-core_2.12:2.3.0\n",
      "spark.master: yarn\n",
      "spark.sql.extensions: io.delta.sql.DeltaSparkSessionExtension\n",
      "spark.ui.proxyBase: /proxy/application_1679580022279_0122\n",
      "spark.yarn.isPython: true\n",
      "spark.submit.deployMode: client\n",
      "spark.yarn.dist.pyFiles: file:///home/ubuntu/.ivy2/jars/io.delta_delta-core_2.12-2.3.0.jar,file:///home/ubuntu/.ivy2/jars/io.delta_delta-storage-2.3.0.jar,file:///home/ubuntu/.ivy2/jars/org.antlr_antlr4-runtime-4.8.jar\n",
      "spark.repl.local.jars: file:///home/ubuntu/.ivy2/jars/io.delta_delta-core_2.12-2.3.0.jar,file:///home/ubuntu/.ivy2/jars/io.delta_delta-storage-2.3.0.jar,file:///home/ubuntu/.ivy2/jars/org.antlr_antlr4-runtime-4.8.jar\n",
      "spark.ui.showConsoleProgress: true\n",
      "spark.sql.catalog.spark_catalog: org.apache.spark.sql.delta.catalog.DeltaCatalog\n",
      "spark.app.submitTime: 1682157706126\n"
     ]
    }
   ],
   "source": [
    "from pyspark import SparkConf\n",
    "\n",
    "conf = SparkConf()\n",
    "config_map = conf.getAll()\n",
    "for key, value in config_map:\n",
    "    print(f\"{key}: {value}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/04/18 16:05:41 WARN SparkSession: Using an existing Spark session; only runtime SQL configurations will take effect.\n",
      "Adaptive Query Execution is enabled\n"
     ]
    }
   ],
   "source": [
    "spark = SparkSession.builder.appName(\"MyApp\").getOrCreate()\n",
    "aqe_enabled = spark.conf.get(\"spark.sql.adaptive.enabled\")\n",
    "print(f\"Adaptive Query Execution is {'enabled' if aqe_enabled == 'true' else 'disabled'}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "arxiv_df = arxiv_df.withColumn(\"main_category\",\n",
    "                   when(split(arxiv_df.category, \"\\\\.\")[0] == \"cs\", \"computer science\")\n",
    "                   .when(split(arxiv_df.category, \"\\\\.\")[0] == \"math\", \"mathematics\")\n",
    "                   .when(split(arxiv_df.category, \"\\\\.\")[0] == \"econ\", \"economics\")\n",
    "                   .when(split(arxiv_df.category, \"\\\\.\")[0] == \"eess\", \"electrical engineering\")\n",
    "                   .when(split(arxiv_df.category, \"\\\\.\")[0] == \"q-bio\", \"quantitative biology\")\n",
    "                   .when(split(arxiv_df.category, \"\\\\.\")[0] == \"q-fin\", \"quantitative finance\")\n",
    "                   .when(split(arxiv_df.category, \"\\\\.\")[0] == \"stat\", \"statistics\")                   \n",
    "                   .otherwise(\"physics\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 1:>                                                          (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+--------------------------------------------------+----------------------------------------------------+---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+-----------+---------------+------------+----------------+\n",
      "|id        |authors                                           |title                                               |abstract                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                         |journal_ref|category       |update_date |main_category   |\n",
      "+----------+--------------------------------------------------+----------------------------------------------------+---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+-----------+---------------+------------+----------------+\n",
      "|2210.02280|Minoru Wakimoto                                   |Mock theta functions and indefinite modular forms II| In this paper, we compute the Zwegers's modification of the mock theta\\nfunctions $\\\\Phi^{[m,0] \\\\, \\\\ast}$ and study the modular transformation\\nproperties of the indefinite modular forms which appear in the explicit formula\\nfor the modified functions $\\\\tilde{\\\\Phi}^{[m,0] \\\\, \\\\ast}$.\\n                                                                                                                                                                                                                                                                                                                                                                                                                             |None       |math.NT math.RT|2022-10-11\\t|mathematics     |\n",
      "|2210.02281|P. Jameson Graber and Alp\\\\'ar R. M\\\\'esz\\\\'aros  |On monotonicity conditions for Mean Field Games     | In this paper we propose two new monotonicity conditions that could serve as\\nsufficient conditions for uniqueness of Nash equilibria in mean field games. In\\nthis study we aim for $unconditional\\\\ uniqueness$ that is independent of the\\nlength of the time horizon, the regularity of the starting distribution of the\\nagents, or the regularization effect of a non-degenerate idiosyncratic noise.\\nThrough a rich class of simple examples we show that these new conditions are\\nnot only in dichotomy with each other, but also with the two widely studied\\nmonotonicity conditions in the literature, the Lasry-Lions monotonicity and\\ndisplacement monotonicity conditions.\\n                                   |None       |math.AP math.OC|2022-10-06\\t|mathematics     |\n",
      "|2210.02282|Cornelia Ott, Hedongliang Liu, Antonia Wachter-Zeh|Covering Properties of Sum-Rank Metric Codes        | The sum-rank metric can be seen as a generalization of both, the rank and the\\nHamming metric. It is well known that sum-rank metric codes outperform rank\\nmetric codes in terms of the required field size to construct maximum distance\\nseparable codes (i.e., the codes achieving the Singleton bound in the\\ncorresponding metric). In this work, we investigate the covering property of\\nsum-rank metric codes to enrich the theory of sum-rank metric codes. We intend\\nto answer the question: what is the minimum cardinality of a code given a\\nsum-rank covering radius? We show the relations of this quantity between\\ndifferent metrics and provide several lower and upper bounds for sum-rank\\nmetric codes.\\n|None       |cs.IT math.IT  |2022-10-06\\t|computer science|\n",
      "+----------+--------------------------------------------------+----------------------------------------------------+---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+-----------+---------------+------------+----------------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "arxiv_df.show(3, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 1:>                                                          (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+----------------------------------------------------+---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+----------------+\n",
      "|id        |title                                               |abstract                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                         |main_category   |\n",
      "+----------+----------------------------------------------------+---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+----------------+\n",
      "|2210.02280|Mock theta functions and indefinite modular forms II| In this paper, we compute the Zwegers's modification of the mock theta\\nfunctions $\\\\Phi^{[m,0] \\\\, \\\\ast}$ and study the modular transformation\\nproperties of the indefinite modular forms which appear in the explicit formula\\nfor the modified functions $\\\\tilde{\\\\Phi}^{[m,0] \\\\, \\\\ast}$.\\n                                                                                                                                                                                                                                                                                                                                                                                                                             |mathematics     |\n",
      "|2210.02281|On monotonicity conditions for Mean Field Games     | In this paper we propose two new monotonicity conditions that could serve as\\nsufficient conditions for uniqueness of Nash equilibria in mean field games. In\\nthis study we aim for $unconditional\\\\ uniqueness$ that is independent of the\\nlength of the time horizon, the regularity of the starting distribution of the\\nagents, or the regularization effect of a non-degenerate idiosyncratic noise.\\nThrough a rich class of simple examples we show that these new conditions are\\nnot only in dichotomy with each other, but also with the two widely studied\\nmonotonicity conditions in the literature, the Lasry-Lions monotonicity and\\ndisplacement monotonicity conditions.\\n                                   |mathematics     |\n",
      "|2210.02282|Covering Properties of Sum-Rank Metric Codes        | The sum-rank metric can be seen as a generalization of both, the rank and the\\nHamming metric. It is well known that sum-rank metric codes outperform rank\\nmetric codes in terms of the required field size to construct maximum distance\\nseparable codes (i.e., the codes achieving the Singleton bound in the\\ncorresponding metric). In this work, we investigate the covering property of\\nsum-rank metric codes to enrich the theory of sum-rank metric codes. We intend\\nto answer the question: what is the minimum cardinality of a code given a\\nsum-rank covering radius? We show the relations of this quantity between\\ndifferent metrics and provide several lower and upper bounds for sum-rank\\nmetric codes.\\n|computer science|\n",
      "+----------+----------------------------------------------------+---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+----------------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# determine the columns that we used for machine learning model\n",
    "clean_arxiv_df = arxiv_df.select(\"id\", \"title\", \"abstract\", \"main_category\")\n",
    "\n",
    "clean_arxiv_df.show(3, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concatenate the title and abstract into a single column\n",
    "clean_arxiv_df = clean_arxiv_df.withColumn('text', concat_ws(' ', clean_arxiv_df['title'], clean_arxiv_df['abstract']))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = Create_ML_pipline()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainingData, testData = clean_arxiv_df.randomSplit([1-test_ratio, test_ratio], seed=24)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====================================================================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Data size:  1763556\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 5:======================================================>  (26 + 1) / 27]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing Data size:  440363\n",
      "====================================================================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "if bprint == 1:\n",
    "    print(\"=\"*100)\n",
    "    print(\"Training Data size: \", trainingData.count())\n",
    "    print(\"Testing Data size: \", testData.count())\n",
    "    print(\"=\"*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/04/22 10:25:38 WARN DAGScheduler: Broadcasting large task binary with size 2.7 MiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 15:=====================================================>  (26 + 1) / 27]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/04/22 10:27:03 WARN DAGScheduler: Broadcasting large task binary with size 2.7 MiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/04/22 10:27:06 WARN DAGScheduler: Broadcasting large task binary with size 6.7 MiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 17:=====================================================>  (26 + 1) / 27]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/04/22 10:28:34 WARN DAGScheduler: Broadcasting large task binary with size 6.7 MiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/04/22 10:28:36 WARN DAGScheduler: Broadcasting large task binary with size 6.7 MiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 19:=====================================================>  (26 + 1) / 27]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/04/22 10:30:22 WARN DAGScheduler: Broadcasting large task binary with size 6.7 MiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 20:>                                                         (0 + 4) / 4]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/04/22 10:30:23 WARN InstanceBuilder$NativeBLAS: Failed to load implementation from:dev.ludovic.netlib.blas.JNIBLAS\n",
      "23/04/22 10:30:23 WARN InstanceBuilder$NativeBLAS: Failed to load implementation from:dev.ludovic.netlib.blas.ForeignLinkerBLAS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/04/22 10:30:24 WARN BLAS: Failed to load implementation from: com.github.fommil.netlib.NativeSystemBLAS\n",
      "23/04/22 10:30:24 WARN BLAS: Failed to load implementation from: com.github.fommil.netlib.NativeRefBLAS\n",
      "23/04/22 10:30:24 WARN DAGScheduler: Broadcasting large task binary with size 6.7 MiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 21:=====================================================>  (26 + 1) / 27]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/04/22 10:30:41 WARN DAGScheduler: Broadcasting large task binary with size 6.7 MiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/04/22 10:30:43 WARN DAGScheduler: Broadcasting large task binary with size 6.7 MiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 23:=====================================================>  (26 + 1) / 27]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/04/22 10:31:00 WARN DAGScheduler: Broadcasting large task binary with size 6.7 MiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/04/22 10:31:01 WARN DAGScheduler: Broadcasting large task binary with size 6.7 MiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 25:=====================================================>  (26 + 1) / 27]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/04/22 10:31:18 WARN DAGScheduler: Broadcasting large task binary with size 6.7 MiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/04/22 10:31:20 WARN DAGScheduler: Broadcasting large task binary with size 6.7 MiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 27:=====================================================>  (26 + 1) / 27]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/04/22 10:31:36 WARN DAGScheduler: Broadcasting large task binary with size 6.7 MiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/04/22 10:31:38 WARN DAGScheduler: Broadcasting large task binary with size 6.7 MiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 29:=====================================================>  (26 + 1) / 27]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/04/22 10:31:55 WARN DAGScheduler: Broadcasting large task binary with size 6.7 MiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/04/22 10:31:56 WARN DAGScheduler: Broadcasting large task binary with size 6.7 MiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 31:=====================================================>  (26 + 1) / 27]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/04/22 10:32:16 WARN DAGScheduler: Broadcasting large task binary with size 6.7 MiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/04/22 10:32:18 WARN DAGScheduler: Broadcasting large task binary with size 6.7 MiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 33:=====================================================>  (26 + 1) / 27]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/04/22 10:32:34 WARN DAGScheduler: Broadcasting large task binary with size 6.7 MiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/04/22 10:32:36 WARN DAGScheduler: Broadcasting large task binary with size 6.7 MiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 35:=====================================================>  (26 + 1) / 27]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/04/22 10:32:52 WARN DAGScheduler: Broadcasting large task binary with size 6.7 MiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/04/22 10:32:54 WARN DAGScheduler: Broadcasting large task binary with size 6.7 MiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 37:=====================================================>  (26 + 1) / 27]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/04/22 10:33:11 WARN DAGScheduler: Broadcasting large task binary with size 6.7 MiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/04/22 10:33:13 WARN DAGScheduler: Broadcasting large task binary with size 6.7 MiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 39:=====================================================>  (26 + 1) / 27]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/04/22 10:33:30 WARN DAGScheduler: Broadcasting large task binary with size 6.7 MiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/04/22 10:33:32 WARN DAGScheduler: Broadcasting large task binary with size 6.7 MiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 41:=====================================================>  (26 + 1) / 27]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/04/22 10:33:48 WARN DAGScheduler: Broadcasting large task binary with size 6.7 MiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/04/22 10:33:50 WARN DAGScheduler: Broadcasting large task binary with size 6.7 MiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 43:=====================================================>  (26 + 1) / 27]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/04/22 10:34:06 WARN DAGScheduler: Broadcasting large task binary with size 6.7 MiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/04/22 10:34:09 WARN DAGScheduler: Broadcasting large task binary with size 6.7 MiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 45:=====================================================>  (26 + 1) / 27]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/04/22 10:34:25 WARN DAGScheduler: Broadcasting large task binary with size 6.7 MiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/04/22 10:34:28 WARN DAGScheduler: Broadcasting large task binary with size 6.7 MiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 47:=====================================================>  (26 + 1) / 27]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/04/22 10:34:44 WARN DAGScheduler: Broadcasting large task binary with size 6.7 MiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/04/22 10:34:47 WARN DAGScheduler: Broadcasting large task binary with size 6.7 MiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 49:=====================================================>  (26 + 1) / 27]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/04/22 10:35:02 WARN DAGScheduler: Broadcasting large task binary with size 6.7 MiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/04/22 10:35:05 WARN DAGScheduler: Broadcasting large task binary with size 6.7 MiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 51:=====================================================>  (26 + 1) / 27]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/04/22 10:35:21 WARN DAGScheduler: Broadcasting large task binary with size 6.7 MiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/04/22 10:35:22 WARN BlockManager: Asked to remove block broadcast_69_piece2, which does not exist\n",
      "23/04/22 10:35:23 WARN DAGScheduler: Broadcasting large task binary with size 6.7 MiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 53:=====================================================>  (26 + 1) / 27]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/04/22 10:35:39 WARN DAGScheduler: Broadcasting large task binary with size 6.7 MiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/04/22 10:35:41 WARN DAGScheduler: Broadcasting large task binary with size 6.7 MiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 55:=====================================================>  (26 + 1) / 27]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/04/22 10:35:58 WARN DAGScheduler: Broadcasting large task binary with size 6.7 MiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/04/22 10:36:00 WARN DAGScheduler: Broadcasting large task binary with size 6.7 MiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 57:=====================================================>  (26 + 1) / 27]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/04/22 10:36:15 WARN DAGScheduler: Broadcasting large task binary with size 6.7 MiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/04/22 10:36:18 WARN DAGScheduler: Broadcasting large task binary with size 6.7 MiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 59:=====================================================>  (26 + 1) / 27]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/04/22 10:36:34 WARN DAGScheduler: Broadcasting large task binary with size 6.7 MiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/04/22 10:36:36 WARN DAGScheduler: Broadcasting large task binary with size 6.7 MiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 61:=====================================================>  (26 + 1) / 27]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/04/22 10:36:53 WARN DAGScheduler: Broadcasting large task binary with size 6.7 MiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/04/22 10:36:55 WARN DAGScheduler: Broadcasting large task binary with size 6.7 MiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 63:=====================================================>  (26 + 1) / 27]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/04/22 10:37:12 WARN DAGScheduler: Broadcasting large task binary with size 6.7 MiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/04/22 10:37:14 WARN DAGScheduler: Broadcasting large task binary with size 6.7 MiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 65:=====================================================>  (26 + 1) / 27]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/04/22 10:37:30 WARN DAGScheduler: Broadcasting large task binary with size 6.7 MiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/04/22 10:37:33 WARN DAGScheduler: Broadcasting large task binary with size 6.7 MiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 67:=====================================================>  (26 + 1) / 27]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/04/22 10:37:49 WARN DAGScheduler: Broadcasting large task binary with size 6.7 MiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/04/22 10:37:51 WARN DAGScheduler: Broadcasting large task binary with size 6.7 MiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 69:=====================================================>  (26 + 1) / 27]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/04/22 10:38:07 WARN DAGScheduler: Broadcasting large task binary with size 6.7 MiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/04/22 10:38:10 WARN DAGScheduler: Broadcasting large task binary with size 6.7 MiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 71:=====================================================>  (26 + 1) / 27]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/04/22 10:38:27 WARN DAGScheduler: Broadcasting large task binary with size 6.7 MiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/04/22 10:38:29 WARN DAGScheduler: Broadcasting large task binary with size 6.7 MiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 73:=====================================================>  (26 + 1) / 27]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/04/22 10:38:47 WARN DAGScheduler: Broadcasting large task binary with size 6.7 MiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/04/22 10:38:49 WARN DAGScheduler: Broadcasting large task binary with size 6.7 MiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 75:=====================================================>  (26 + 1) / 27]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/04/22 10:39:07 WARN DAGScheduler: Broadcasting large task binary with size 6.7 MiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/04/22 10:39:09 WARN DAGScheduler: Broadcasting large task binary with size 6.7 MiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 77:=====================================================>  (26 + 1) / 27]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/04/22 10:39:26 WARN DAGScheduler: Broadcasting large task binary with size 6.7 MiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/04/22 10:39:28 WARN DAGScheduler: Broadcasting large task binary with size 6.7 MiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 79:=====================================================>  (26 + 1) / 27]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/04/22 10:39:46 WARN DAGScheduler: Broadcasting large task binary with size 6.7 MiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/04/22 10:39:48 WARN DAGScheduler: Broadcasting large task binary with size 6.7 MiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 81:=====================================================>  (26 + 1) / 27]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/04/22 10:40:06 WARN DAGScheduler: Broadcasting large task binary with size 6.7 MiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/04/22 10:40:08 WARN DAGScheduler: Broadcasting large task binary with size 6.7 MiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 83:=====================================================>  (26 + 1) / 27]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/04/22 10:40:27 WARN DAGScheduler: Broadcasting large task binary with size 6.7 MiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/04/22 10:40:30 WARN DAGScheduler: Broadcasting large task binary with size 6.7 MiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 85:=====================================================>  (26 + 1) / 27]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/04/22 10:40:48 WARN DAGScheduler: Broadcasting large task binary with size 6.7 MiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/04/22 10:40:51 WARN DAGScheduler: Broadcasting large task binary with size 6.7 MiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 87:=====================================================>  (26 + 1) / 27]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/04/22 10:41:10 WARN DAGScheduler: Broadcasting large task binary with size 6.7 MiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/04/22 10:41:12 WARN DAGScheduler: Broadcasting large task binary with size 6.7 MiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 89:=====================================================>  (26 + 1) / 27]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/04/22 10:41:32 WARN DAGScheduler: Broadcasting large task binary with size 6.7 MiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/04/22 10:41:34 WARN DAGScheduler: Broadcasting large task binary with size 6.7 MiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 91:=====================================================>  (26 + 1) / 27]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/04/22 10:41:54 WARN DAGScheduler: Broadcasting large task binary with size 6.7 MiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/04/22 10:41:57 WARN DAGScheduler: Broadcasting large task binary with size 6.7 MiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 93:=====================================================>  (26 + 1) / 27]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/04/22 10:42:16 WARN DAGScheduler: Broadcasting large task binary with size 6.7 MiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/04/22 10:42:18 WARN DAGScheduler: Broadcasting large task binary with size 6.7 MiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 95:=====================================================>  (26 + 1) / 27]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/04/22 10:42:40 WARN DAGScheduler: Broadcasting large task binary with size 6.7 MiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/04/22 10:42:42 WARN DAGScheduler: Broadcasting large task binary with size 6.7 MiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 97:=====================================================>  (26 + 1) / 27]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/04/22 10:43:00 WARN DAGScheduler: Broadcasting large task binary with size 6.7 MiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/04/22 10:43:02 WARN DAGScheduler: Broadcasting large task binary with size 6.7 MiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 99:=====================================================>  (26 + 1) / 27]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/04/22 10:43:20 WARN DAGScheduler: Broadcasting large task binary with size 6.7 MiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/04/22 10:43:21 WARN DAGScheduler: Broadcasting large task binary with size 6.7 MiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 101:====================================================>  (26 + 1) / 27]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/04/22 10:43:39 WARN DAGScheduler: Broadcasting large task binary with size 6.7 MiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/04/22 10:43:42 WARN DAGScheduler: Broadcasting large task binary with size 6.7 MiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 103:====================================================>  (26 + 1) / 27]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/04/22 10:43:59 WARN DAGScheduler: Broadcasting large task binary with size 6.7 MiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/04/22 10:44:01 WARN DAGScheduler: Broadcasting large task binary with size 6.7 MiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 105:====================================================>  (26 + 1) / 27]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/04/22 10:44:19 WARN DAGScheduler: Broadcasting large task binary with size 6.7 MiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/04/22 10:44:22 WARN DAGScheduler: Broadcasting large task binary with size 6.7 MiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 107:====================================================>  (26 + 1) / 27]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/04/22 10:44:40 WARN DAGScheduler: Broadcasting large task binary with size 6.7 MiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/04/22 10:44:42 WARN DAGScheduler: Broadcasting large task binary with size 6.7 MiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 109:====================================================>  (26 + 1) / 27]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/04/22 10:45:00 WARN DAGScheduler: Broadcasting large task binary with size 6.7 MiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/04/22 10:45:02 WARN DAGScheduler: Broadcasting large task binary with size 6.7 MiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 111:====================================================>  (26 + 1) / 27]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/04/22 10:45:20 WARN DAGScheduler: Broadcasting large task binary with size 6.7 MiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/04/22 10:45:21 WARN BlockManager: Asked to remove block broadcast_159, which does not exist\n",
      "23/04/22 10:45:21 WARN BlockManager: Asked to remove block broadcast_159_piece0, which does not exist\n",
      "23/04/22 10:45:23 WARN DAGScheduler: Broadcasting large task binary with size 6.7 MiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 113:====================================================>  (26 + 1) / 27]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/04/22 10:45:40 WARN DAGScheduler: Broadcasting large task binary with size 6.7 MiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/04/22 10:45:43 WARN DAGScheduler: Broadcasting large task binary with size 6.7 MiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 115:====================================================>  (26 + 1) / 27]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/04/22 10:46:01 WARN DAGScheduler: Broadcasting large task binary with size 6.7 MiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/04/22 10:46:03 WARN DAGScheduler: Broadcasting large task binary with size 6.7 MiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 117:====================================================>  (26 + 1) / 27]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/04/22 10:46:21 WARN DAGScheduler: Broadcasting large task binary with size 6.7 MiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/04/22 10:46:23 WARN DAGScheduler: Broadcasting large task binary with size 6.7 MiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 119:====================================================>  (26 + 1) / 27]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/04/22 10:46:41 WARN DAGScheduler: Broadcasting large task binary with size 6.7 MiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/04/22 10:46:43 WARN DAGScheduler: Broadcasting large task binary with size 6.7 MiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 121:====================================================>  (26 + 1) / 27]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/04/22 10:47:02 WARN DAGScheduler: Broadcasting large task binary with size 6.7 MiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/04/22 10:47:04 WARN DAGScheduler: Broadcasting large task binary with size 6.7 MiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 123:====================================================>  (26 + 1) / 27]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/04/22 10:47:26 WARN DAGScheduler: Broadcasting large task binary with size 6.7 MiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/04/22 10:47:28 WARN DAGScheduler: Broadcasting large task binary with size 6.7 MiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 125:====================================================>  (26 + 1) / 27]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/04/22 10:47:50 WARN DAGScheduler: Broadcasting large task binary with size 6.7 MiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/04/22 10:47:59 WARN DAGScheduler: Broadcasting large task binary with size 6.7 MiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 128:>                                                        (0 + 3) / 4]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/04/22 10:48:16 WARN DAGScheduler: Broadcasting large task binary with size 6.7 MiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/04/22 10:48:18 WARN DAGScheduler: Broadcasting large task binary with size 6.7 MiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 129:====================================================>  (26 + 1) / 27]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/04/22 10:48:35 WARN DAGScheduler: Broadcasting large task binary with size 6.7 MiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/04/22 10:48:38 WARN DAGScheduler: Broadcasting large task binary with size 6.7 MiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 131:====================================================>  (26 + 1) / 27]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/04/22 10:48:55 WARN DAGScheduler: Broadcasting large task binary with size 6.7 MiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/04/22 10:48:58 WARN DAGScheduler: Broadcasting large task binary with size 6.7 MiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 133:====================================================>  (26 + 1) / 27]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/04/22 10:49:15 WARN DAGScheduler: Broadcasting large task binary with size 6.7 MiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/04/22 10:49:17 WARN DAGScheduler: Broadcasting large task binary with size 6.7 MiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 135:====================================================>  (26 + 1) / 27]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/04/22 10:49:35 WARN DAGScheduler: Broadcasting large task binary with size 6.7 MiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/04/22 10:49:37 WARN DAGScheduler: Broadcasting large task binary with size 6.7 MiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 137:====================================================>  (26 + 1) / 27]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/04/22 10:49:54 WARN DAGScheduler: Broadcasting large task binary with size 6.7 MiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/04/22 10:49:57 WARN DAGScheduler: Broadcasting large task binary with size 6.7 MiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 139:====================================================>  (26 + 1) / 27]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/04/22 10:50:15 WARN DAGScheduler: Broadcasting large task binary with size 6.7 MiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/04/22 10:50:17 WARN DAGScheduler: Broadcasting large task binary with size 6.7 MiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 142:>                                                        (0 + 4) / 4]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/04/22 10:50:35 WARN DAGScheduler: Broadcasting large task binary with size 6.7 MiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/04/22 10:50:37 WARN DAGScheduler: Broadcasting large task binary with size 6.7 MiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 143:====================================================>  (26 + 1) / 27]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/04/22 10:50:54 WARN DAGScheduler: Broadcasting large task binary with size 6.7 MiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/04/22 10:50:57 WARN DAGScheduler: Broadcasting large task binary with size 6.7 MiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 145:====================================================>  (26 + 1) / 27]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/04/22 10:51:14 WARN DAGScheduler: Broadcasting large task binary with size 6.7 MiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/04/22 10:51:16 WARN DAGScheduler: Broadcasting large task binary with size 6.7 MiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 147:====================================================>  (26 + 1) / 27]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/04/22 10:51:33 WARN DAGScheduler: Broadcasting large task binary with size 6.7 MiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/04/22 10:51:36 WARN DAGScheduler: Broadcasting large task binary with size 6.7 MiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 149:====================================================>  (26 + 1) / 27]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/04/22 10:51:54 WARN DAGScheduler: Broadcasting large task binary with size 6.7 MiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/04/22 10:51:57 WARN DAGScheduler: Broadcasting large task binary with size 6.7 MiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 151:====================================================>  (26 + 1) / 27]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/04/22 10:52:15 WARN DAGScheduler: Broadcasting large task binary with size 6.7 MiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/04/22 10:52:17 WARN DAGScheduler: Broadcasting large task binary with size 6.7 MiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 153:====================================================>  (26 + 1) / 27]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/04/22 10:52:35 WARN DAGScheduler: Broadcasting large task binary with size 6.7 MiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/04/22 10:52:37 WARN DAGScheduler: Broadcasting large task binary with size 6.7 MiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 155:====================================================>  (26 + 1) / 27]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/04/22 10:52:54 WARN DAGScheduler: Broadcasting large task binary with size 6.7 MiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/04/22 10:52:57 WARN DAGScheduler: Broadcasting large task binary with size 6.7 MiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 157:====================================================>  (26 + 1) / 27]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/04/22 10:53:16 WARN DAGScheduler: Broadcasting large task binary with size 6.7 MiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/04/22 10:53:19 WARN DAGScheduler: Broadcasting large task binary with size 6.7 MiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 159:====================================================>  (26 + 1) / 27]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/04/22 10:53:37 WARN DAGScheduler: Broadcasting large task binary with size 6.7 MiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/04/22 10:53:39 WARN DAGScheduler: Broadcasting large task binary with size 6.7 MiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 161:====================================================>  (26 + 1) / 27]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/04/22 10:53:58 WARN DAGScheduler: Broadcasting large task binary with size 6.7 MiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/04/22 10:54:01 WARN DAGScheduler: Broadcasting large task binary with size 6.7 MiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 163:====================================================>  (26 + 1) / 27]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/04/22 10:54:18 WARN DAGScheduler: Broadcasting large task binary with size 6.7 MiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/04/22 10:54:20 WARN BlockManager: Asked to remove block broadcast_237_piece4, which does not exist\n",
      "23/04/22 10:54:20 WARN BlockManager: Asked to remove block broadcast_237_piece3, which does not exist\n",
      "23/04/22 10:54:20 WARN BlockManager: Asked to remove block broadcast_237_piece1, which does not exist\n",
      "23/04/22 10:54:20 WARN BlockManager: Asked to remove block broadcast_237_piece2, which does not exist\n",
      "23/04/22 10:54:21 WARN BlockManagerMaster: Failed to remove broadcast 237 with removeFromMaster = true - Block broadcast_237_piece2 does not exist\n",
      "org.apache.spark.SparkException: Block broadcast_237_piece2 does not exist\n",
      "\tat org.apache.spark.errors.SparkCoreErrors$.blockDoesNotExistError(SparkCoreErrors.scala:234)\n",
      "\tat org.apache.spark.storage.BlockInfoManager.blockInfo(BlockInfoManager.scala:237)\n",
      "\tat org.apache.spark.storage.BlockInfoManager.removeBlock(BlockInfoManager.scala:500)\n",
      "\tat org.apache.spark.storage.BlockManager.removeBlockInternal(BlockManager.scala:2011)\n",
      "\tat org.apache.spark.storage.BlockManager.removeBlock(BlockManager.scala:1977)\n",
      "\tat org.apache.spark.storage.BlockManager.$anonfun$removeBroadcast$3(BlockManager.scala:1963)\n",
      "\tat org.apache.spark.storage.BlockManager.$anonfun$removeBroadcast$3$adapted(BlockManager.scala:1963)\n",
      "\tat scala.collection.Iterator.foreach(Iterator.scala:943)\n",
      "\tat scala.collection.Iterator.foreach$(Iterator.scala:943)\n",
      "\tat scala.collection.AbstractIterator.foreach(Iterator.scala:1431)\n",
      "\tat org.apache.spark.storage.BlockManager.removeBroadcast(BlockManager.scala:1963)\n",
      "\tat org.apache.spark.storage.BlockManagerStorageEndpoint$$anonfun$receiveAndReply$1.$anonfun$applyOrElse$4(BlockManagerStorageEndpoint.scala:69)\n",
      "\tat scala.runtime.java8.JFunction0$mcI$sp.apply(JFunction0$mcI$sp.java:23)\n",
      "\tat org.apache.spark.storage.BlockManagerStorageEndpoint.$anonfun$doAsync$1(BlockManagerStorageEndpoint.scala:89)\n",
      "\tat scala.concurrent.Future$.$anonfun$apply$1(Future.scala:659)\n",
      "\tat scala.util.Success.$anonfun$map$1(Try.scala:255)\n",
      "\tat scala.util.Success.map(Try.scala:213)\n",
      "\tat scala.concurrent.Future.$anonfun$map$1(Future.scala:292)\n",
      "\tat scala.concurrent.impl.Promise.liftedTree1$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:750)\n",
      "23/04/22 10:54:21 ERROR ContextCleaner: Error cleaning broadcast 237\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.removeBroadcast(BlockManagerMaster.scala:209)\n",
      "\tat org.apache.spark.broadcast.TorrentBroadcast$.unpersist(TorrentBroadcast.scala:351)\n",
      "\tat org.apache.spark.broadcast.TorrentBroadcastFactory.unbroadcast(TorrentBroadcastFactory.scala:45)\n",
      "\tat org.apache.spark.broadcast.BroadcastManager.unbroadcast(BroadcastManager.scala:79)\n",
      "\tat org.apache.spark.ContextCleaner.doCleanupBroadcast(ContextCleaner.scala:256)\n",
      "\tat org.apache.spark.ContextCleaner.$anonfun$keepCleaning$3(ContextCleaner.scala:204)\n",
      "\tat org.apache.spark.ContextCleaner.$anonfun$keepCleaning$3$adapted(ContextCleaner.scala:195)\n",
      "\tat scala.Option.foreach(Option.scala:407)\n",
      "\tat org.apache.spark.ContextCleaner.$anonfun$keepCleaning$1(ContextCleaner.scala:195)\n",
      "\tat org.apache.spark.util.Utils$.tryOrStopSparkContext(Utils.scala:1446)\n",
      "\tat org.apache.spark.ContextCleaner.org$apache$spark$ContextCleaner$$keepCleaning(ContextCleaner.scala:189)\n",
      "\tat org.apache.spark.ContextCleaner$$anon$1.run(ContextCleaner.scala:79)\n",
      "Caused by: org.apache.spark.SparkException: Block broadcast_237_piece2 does not exist\n",
      "\tat org.apache.spark.errors.SparkCoreErrors$.blockDoesNotExistError(SparkCoreErrors.scala:234)\n",
      "\tat org.apache.spark.storage.BlockInfoManager.blockInfo(BlockInfoManager.scala:237)\n",
      "\tat org.apache.spark.storage.BlockInfoManager.removeBlock(BlockInfoManager.scala:500)\n",
      "\tat org.apache.spark.storage.BlockManager.removeBlockInternal(BlockManager.scala:2011)\n",
      "\tat org.apache.spark.storage.BlockManager.removeBlock(BlockManager.scala:1977)\n",
      "\tat org.apache.spark.storage.BlockManager.$anonfun$removeBroadcast$3(BlockManager.scala:1963)\n",
      "\tat org.apache.spark.storage.BlockManager.$anonfun$removeBroadcast$3$adapted(BlockManager.scala:1963)\n",
      "\tat scala.collection.Iterator.foreach(Iterator.scala:943)\n",
      "\tat scala.collection.Iterator.foreach$(Iterator.scala:943)\n",
      "\tat scala.collection.AbstractIterator.foreach(Iterator.scala:1431)\n",
      "\tat org.apache.spark.storage.BlockManager.removeBroadcast(BlockManager.scala:1963)\n",
      "\tat org.apache.spark.storage.BlockManagerStorageEndpoint$$anonfun$receiveAndReply$1.$anonfun$applyOrElse$4(BlockManagerStorageEndpoint.scala:69)\n",
      "\tat scala.runtime.java8.JFunction0$mcI$sp.apply(JFunction0$mcI$sp.java:23)\n",
      "\tat org.apache.spark.storage.BlockManagerStorageEndpoint.$anonfun$doAsync$1(BlockManagerStorageEndpoint.scala:89)\n",
      "\tat scala.concurrent.Future$.$anonfun$apply$1(Future.scala:659)\n",
      "\tat scala.util.Success.$anonfun$map$1(Try.scala:255)\n",
      "\tat scala.util.Success.map(Try.scala:213)\n",
      "\tat scala.concurrent.Future.$anonfun$map$1(Future.scala:292)\n",
      "\tat scala.concurrent.impl.Promise.liftedTree1$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:750)\n",
      "23/04/22 10:54:21 WARN DAGScheduler: Broadcasting large task binary with size 6.7 MiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 165:====================================================>  (26 + 1) / 27]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/04/22 10:54:39 WARN DAGScheduler: Broadcasting large task binary with size 6.7 MiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/04/22 10:54:41 WARN DAGScheduler: Broadcasting large task binary with size 6.7 MiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 167:====================================================>  (26 + 1) / 27]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/04/22 10:54:59 WARN DAGScheduler: Broadcasting large task binary with size 6.7 MiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/04/22 10:55:04 WARN DAGScheduler: Broadcasting large task binary with size 6.7 MiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 169:====================================================>  (26 + 1) / 27]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/04/22 10:55:22 WARN DAGScheduler: Broadcasting large task binary with size 6.7 MiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/04/22 10:55:24 WARN DAGScheduler: Broadcasting large task binary with size 6.7 MiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 171:====================================================>  (26 + 1) / 27]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/04/22 10:55:41 WARN DAGScheduler: Broadcasting large task binary with size 6.7 MiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/04/22 10:55:44 WARN DAGScheduler: Broadcasting large task binary with size 6.7 MiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 173:====================================================>  (26 + 1) / 27]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/04/22 10:56:02 WARN DAGScheduler: Broadcasting large task binary with size 6.7 MiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/04/22 10:56:05 WARN DAGScheduler: Broadcasting large task binary with size 6.7 MiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 175:====================================================>  (26 + 1) / 27]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/04/22 10:56:22 WARN DAGScheduler: Broadcasting large task binary with size 6.7 MiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/04/22 10:56:25 WARN DAGScheduler: Broadcasting large task binary with size 6.7 MiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 177:====================================================>  (26 + 1) / 27]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/04/22 10:56:45 WARN DAGScheduler: Broadcasting large task binary with size 6.7 MiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/04/22 10:56:47 WARN DAGScheduler: Broadcasting large task binary with size 6.7 MiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 179:====================================================>  (26 + 1) / 27]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/04/22 10:57:06 WARN DAGScheduler: Broadcasting large task binary with size 6.7 MiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/04/22 10:57:09 WARN DAGScheduler: Broadcasting large task binary with size 6.7 MiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 181:====================================================>  (26 + 1) / 27]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/04/22 10:57:28 WARN DAGScheduler: Broadcasting large task binary with size 6.7 MiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/04/22 10:57:30 WARN DAGScheduler: Broadcasting large task binary with size 6.7 MiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 183:====================================================>  (26 + 1) / 27]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/04/22 10:57:47 WARN DAGScheduler: Broadcasting large task binary with size 6.7 MiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/04/22 10:57:49 WARN DAGScheduler: Broadcasting large task binary with size 6.7 MiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 185:====================================================>  (26 + 1) / 27]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/04/22 10:58:10 WARN DAGScheduler: Broadcasting large task binary with size 6.7 MiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/04/22 10:58:14 WARN DAGScheduler: Broadcasting large task binary with size 6.7 MiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 187:====================================================>  (26 + 1) / 27]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/04/22 10:58:32 WARN DAGScheduler: Broadcasting large task binary with size 6.7 MiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/04/22 10:58:34 WARN DAGScheduler: Broadcasting large task binary with size 6.7 MiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 189:====================================================>  (26 + 1) / 27]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/04/22 10:58:53 WARN DAGScheduler: Broadcasting large task binary with size 6.7 MiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/04/22 10:58:57 WARN DAGScheduler: Broadcasting large task binary with size 6.7 MiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 191:====================================================>  (26 + 1) / 27]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/04/22 10:59:17 WARN DAGScheduler: Broadcasting large task binary with size 6.7 MiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/04/22 10:59:19 WARN DAGScheduler: Broadcasting large task binary with size 6.7 MiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 193:====================================================>  (26 + 1) / 27]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/04/22 10:59:36 WARN DAGScheduler: Broadcasting large task binary with size 6.7 MiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/04/22 10:59:39 WARN DAGScheduler: Broadcasting large task binary with size 6.7 MiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 195:====================================================>  (26 + 1) / 27]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/04/22 10:59:55 WARN DAGScheduler: Broadcasting large task binary with size 6.7 MiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/04/22 10:59:58 WARN DAGScheduler: Broadcasting large task binary with size 6.7 MiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 197:====================================================>  (26 + 1) / 27]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/04/22 11:00:15 WARN DAGScheduler: Broadcasting large task binary with size 6.7 MiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/04/22 11:00:18 WARN DAGScheduler: Broadcasting large task binary with size 6.7 MiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 199:====================================================>  (26 + 1) / 27]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/04/22 11:00:37 WARN DAGScheduler: Broadcasting large task binary with size 6.7 MiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/04/22 11:00:38 WARN BlockManager: Asked to remove block broadcast_291_piece4, which does not exist\n",
      "23/04/22 11:00:38 WARN BlockManager: Asked to remove block broadcast_291, which does not exist\n",
      "23/04/22 11:00:38 WARN BlockManager: Asked to remove block broadcast_291_piece2, which does not exist\n",
      "23/04/22 11:00:38 WARN BlockManager: Asked to remove block broadcast_291_piece0, which does not exist\n",
      "23/04/22 11:00:39 WARN DAGScheduler: Broadcasting large task binary with size 6.7 MiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 201:====================================================>  (26 + 1) / 27]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/04/22 11:00:56 WARN DAGScheduler: Broadcasting large task binary with size 6.7 MiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/04/22 11:00:58 WARN DAGScheduler: Broadcasting large task binary with size 6.7 MiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 203:==================================================>    (25 + 2) / 27]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/04/22 11:01:21 WARN DAGScheduler: Broadcasting large task binary with size 6.7 MiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/04/22 11:01:23 WARN DAGScheduler: Broadcasting large task binary with size 6.7 MiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 205:====================================================>  (26 + 1) / 27]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/04/22 11:01:44 WARN DAGScheduler: Broadcasting large task binary with size 6.7 MiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/04/22 11:01:46 WARN DAGScheduler: Broadcasting large task binary with size 6.7 MiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 207:====================================================>  (26 + 1) / 27]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/04/22 11:02:06 WARN DAGScheduler: Broadcasting large task binary with size 6.7 MiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/04/22 11:02:09 WARN DAGScheduler: Broadcasting large task binary with size 6.7 MiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 209:====================================================>  (26 + 1) / 27]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/04/22 11:02:27 WARN DAGScheduler: Broadcasting large task binary with size 6.7 MiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/04/22 11:02:31 WARN DAGScheduler: Broadcasting large task binary with size 6.7 MiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 211:====================================================>  (26 + 1) / 27]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/04/22 11:02:58 WARN DAGScheduler: Broadcasting large task binary with size 6.7 MiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/04/22 11:03:00 WARN DAGScheduler: Broadcasting large task binary with size 6.7 MiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 213:====================================================>  (26 + 1) / 27]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/04/22 11:03:17 WARN DAGScheduler: Broadcasting large task binary with size 6.7 MiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/04/22 11:03:19 WARN DAGScheduler: Broadcasting large task binary with size 6.7 MiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 215:==================================================>    (25 + 2) / 27]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/04/22 11:03:44 WARN DAGScheduler: Broadcasting large task binary with size 6.7 MiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/04/22 11:03:47 WARN DAGScheduler: Broadcasting large task binary with size 6.7 MiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 217:====================================================>  (26 + 1) / 27]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/04/22 11:04:07 WARN DAGScheduler: Broadcasting large task binary with size 6.7 MiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/04/22 11:04:18 WARN DAGScheduler: Broadcasting large task binary with size 6.7 MiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 219:====================================================>  (26 + 1) / 27]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/04/22 11:04:36 WARN DAGScheduler: Broadcasting large task binary with size 6.7 MiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# Fit the model\n",
    "ML_model = pipeline.fit(trainingData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/04/21 04:13:20 WARN TaskSetManager: Stage 229 contains a task of very large size (4849 KiB). The maximum recommended task size is 1000 KiB.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/04/21 04:13:22 WARN TaskSetManager: Stage 233 contains a task of very large size (4184 KiB). The maximum recommended task size is 1000 KiB.\n",
      "23/04/21 04:13:23 WARN TaskSetManager: Stage 237 contains a task of very large size (16725 KiB). The maximum recommended task size is 1000 KiB.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# save the machine learning model\n",
    "pipelinePath = 'hdfs:///Dat500_Group09/result/ML_model'\n",
    "ML_model.write().overwrite().save(pipelinePath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the saved machine learning model\n",
    "#from pyspark.ml import PipelineModel\n",
    "#savedPipelineModel = PipelineModel.load(pipelinePath)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make predictions on the testing data\n",
    "df_Prediction = ML_model.transform(testData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/04/21 05:35:45 WARN DAGScheduler: Broadcasting large task binary with size 22.7 MiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 223:>                                                        (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+----------------+-----+----------+\n",
      "|        id|   main_category|label|prediction|\n",
      "+----------+----------------+-----+----------+\n",
      "|2210.02287|computer science|  2.0|       2.0|\n",
      "|2210.02293|         physics|  0.0|       0.0|\n",
      "|2210.02298|         physics|  0.0|       5.0|\n",
      "+----------+----------------+-----+----------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# Print the dataframe with the original main_category and the predicted one\n",
    "df_Prediction = df_Prediction.select(\"id\", \"main_category\", \"label\", \"prediction\")\n",
    "df_Prediction.show(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/04/21 05:35:57 WARN DAGScheduler: Broadcasting large task binary with size 22.7 MiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 224:====================================================>  (26 + 1) / 27]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy = 0.859028\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# Evaluate the model using the F1 score\n",
    "evaluator = MulticlassClassificationEvaluator(labelCol=\"label\", predictionCol=\"prediction\", metricName=\"accuracy\")\n",
    "accuracy = evaluator.evaluate(df_Prediction)\n",
    "print(\"accuracy = %g\" % accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/04/18 16:34:43 WARN DAGScheduler: Broadcasting large task binary with size 22.7 MiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 47:=====================================================>  (26 + 1) / 27]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy = 0.848034\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# Evaluate the performance of the model\n",
    "evaluator = MulticlassClassificationEvaluator(labelCol=\"label\", predictionCol=\"prediction\", metricName=\"accuracy\")\n",
    "accuracy = evaluator.evaluate(df_Prediction)\n",
    "print(\"Accuracy = %g\" % accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "update delta table\n",
      "23/04/21 05:40:32 WARN package: Truncated the string representation of a plan since it was too large. This behavior can be adjusted by setting 'spark.sql.debug.maxToStringFields'.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/04/21 05:40:54 WARN DAGScheduler: Broadcasting large task binary with size 22.7 MiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 236:====================================================>  (26 + 1) / 27]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/04/21 05:41:37 WARN DAGScheduler: Broadcasting large task binary with size 22.7 MiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# check if the Delta table exists  \n",
    "# DeltaTable.isDeltaTable(spark, \"spark-warehouse/table1\") # True \n",
    "#DeltaTable\n",
    "if DeltaTable.isDeltaTable(spark, delta_table_path):\n",
    "    print(\"update delta table\")\n",
    "    deltaTable = DeltaTable.forPath(spark, delta_table_path)\n",
    "    #\"target.id = updates.id and target.main_category = updates.main_category\") \\\n",
    "    deltaTable.alias(\"target\") \\\n",
    "        .merge(\n",
    "        source = df_Prediction.alias(\"updates\"),\n",
    "        condition = \"target.id = updates.id\") \\\n",
    "        .whenMatchedUpdate( set = \n",
    "        {\n",
    "            \"label\": \"updates.label\",\n",
    "            \"prediction\": \"updates.prediction\"     \n",
    "        }) \\\n",
    "        .whenNotMatchedInsert(values =\n",
    "        {\n",
    "            \"id\": \"updates.id\",\n",
    "            \"main_category\": \"updates.main_category\",\n",
    "            \"label\": \"updates.label\",\n",
    "            \"prediction\": \"updates.prediction\"        \n",
    "        }) \\\n",
    "        .execute()\n",
    "else: # file not exists\n",
    "    print(\"Create delta table first time\")\n",
    "    df_Prediction.write.format(\"delta\").save(delta_table_path)\n",
    "    #df_Prediction.write.format(\"delta\").partitionBy(\"main_category\").save(delta_table_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+----------------+-----+----------+\n",
      "|       id|   main_category|label|prediction|\n",
      "+---------+----------------+-----+----------+\n",
      "|0704.0079|     mathematics|  1.0|       1.0|\n",
      "|0704.0153|         physics|  0.0|       1.0|\n",
      "|0704.0192|         physics|  0.0|       0.0|\n",
      "|0704.0202|         physics|  0.0|       0.0|\n",
      "|0704.0217|computer science|  2.0|       2.0|\n",
      "|0704.0233|         physics|  0.0|       0.0|\n",
      "|0704.0280|         physics|  0.0|       0.0|\n",
      "|0704.0304|computer science|  2.0|       5.0|\n",
      "|0704.0306|         physics|  0.0|       0.0|\n",
      "|0704.0451|         physics|  0.0|       0.0|\n",
      "+---------+----------------+-----+----------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df = spark.read.format(\"delta\").load(delta_table_path)\n",
    "df.show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "440363"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.count()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
